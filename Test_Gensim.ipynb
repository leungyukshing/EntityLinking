{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Notebook\n",
    "In this notebook, I try to use gensim to do word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From Pre-trained Txt File\n",
    "First I have to load from pretrained data from txt file.\n",
    "Load all data may take more than 30mins on my laptop, so it would be better to set a limit.\n",
    "\n",
    "Also, I save model as a bin file for later use, which will be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/Tencent_AILab_ChineseEmbedding/Tencent_AILab_ChineseEmbedding.txt'\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(file, binary=False, limit=4000000)\n",
    "wv_from_text.init_sims(replace=True) # save memory to run faster\n",
    "wv_from_text.save('./test_40.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('安徽理工大学', 0.8747442960739136),\n",
       " ('安徽财经大学', 0.8564743995666504),\n",
       " ('安徽工程大学', 0.8556878566741943),\n",
       " ('合肥工业大学', 0.8495832085609436),\n",
       " ('铜陵学院', 0.8441342115402222),\n",
       " ('皖西学院', 0.831087589263916),\n",
       " ('安师大', 0.828484058380127),\n",
       " ('安徽师范大学', 0.82568359375),\n",
       " ('巢湖学院', 0.8209227323532104),\n",
       " ('安庆师范学院', 0.8206217288970947)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_text.most_similar('安徽工业大学')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From bin File\n",
    "In practical use, I load model from bin file, which is fast and can be finish in few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('./test_10.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Function Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_similar\n",
    "This function accepts a query word, and return all relative words based on their similarities. Fro similarity here, the model use Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('中兴手机', 0.8854156732559204),\n",
       " ('联想手机', 0.8789077997207642),\n",
       " ('酷派手机', 0.8411391377449036),\n",
       " ('lg手机', 0.8332662582397461),\n",
       " ('moto手机', 0.7984577417373657),\n",
       " ('夏普手机', 0.7713048458099365),\n",
       " ('波导手机', 0.7678113579750061),\n",
       " ('联想移动', 0.7676339149475098),\n",
       " ('摩托罗拉手机', 0.7662297487258911),\n",
       " ('金立手机', 0.7615381479263306)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('tcl手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68678486"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('tcl集团','tcl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get embedding vector\n",
    "I can get a word's embedding vector to compute different scores based on different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "<class 'numpy.float32'>\n",
      "[ 0.03383196 -0.17869404  0.05238409 -0.05279097 -0.00203355 -0.02550736\n",
      "  0.00590293  0.02501949 -0.00388571 -0.05073139 -0.01879838  0.03750166\n",
      " -0.0429432  -0.01066442 -0.05733578  0.00487093 -0.16680478 -0.01408257\n",
      " -0.0126278  -0.00468757 -0.10181407 -0.04922124  0.0236799   0.08008453\n",
      " -0.11077128 -0.07158781 -0.02592197  0.06746666  0.09003778  0.12129757\n",
      "  0.13584374 -0.1022609  -0.06597835  0.17919205 -0.06002511 -0.04983841\n",
      "  0.01059006  0.0650035  -0.07256994 -0.07949052 -0.0896534  -0.04846947\n",
      "  0.00800002  0.11383043 -0.00127295 -0.05526561 -0.04370026 -0.0228006\n",
      " -0.04405353 -0.0121503   0.07846978  0.08052275  0.0815885  -0.13652511\n",
      "  0.06184749  0.03619649 -0.06231837  0.14912842 -0.03663978  0.02024984\n",
      " -0.05889713  0.02001837  0.12010405 -0.03547539 -0.09309956 -0.02752634\n",
      " -0.04178631  0.06795077  0.01024363  0.0994449  -0.10717772  0.05576936\n",
      "  0.05840507  0.13200833 -0.05574288  0.03868127  0.04881038  0.13337329\n",
      " -0.08431953  0.02521278 -0.00306863  0.02050138 -0.06572923 -0.00385173\n",
      " -0.02489041 -0.08538419 -0.12980312  0.08381137 -0.04919851 -0.04869763\n",
      " -0.02436172  0.10454002 -0.01564568 -0.04224505 -0.04857869  0.05226053\n",
      " -0.01714259  0.07407171  0.00249427 -0.0687694   0.01360639 -0.06325284\n",
      "  0.14762929 -0.02858283  0.04597255  0.02513555  0.05502885 -0.0674404\n",
      "  0.04826073  0.02300073 -0.08267169 -0.08046162 -0.06820408 -0.09429948\n",
      " -0.11810273  0.07319968  0.0753824   0.04694255 -0.10483349 -0.06173606\n",
      " -0.02480612  0.01654308  0.06271996  0.02504442 -0.06495827 -0.05551936\n",
      " -0.01932177  0.1092298  -0.01103776 -0.00452561  0.03648753 -0.12940903\n",
      "  0.05286533 -0.03412102  0.02569271 -0.00742081  0.05319896 -0.09222423\n",
      " -0.11188249  0.06527138 -0.0143853  -0.03251973  0.03244714  0.01402122\n",
      "  0.18648951  0.04005374  0.00404414  0.04630066  0.10582357 -0.0527453\n",
      " -0.0346881   0.01979882 -0.08074406 -0.0864142   0.02449014  0.02980591\n",
      "  0.07393049  0.07380979  0.06716657  0.08196516  0.06832787  0.00765227\n",
      " -0.10884365  0.15204634  0.05733997  0.03701952 -0.10681298  0.13636205\n",
      "  0.02380347 -0.08935397 -0.00780497 -0.00283165 -0.10343786 -0.05033709\n",
      " -0.10484055 -0.10202236 -0.03306872 -0.01152828  0.02435488  0.00238196\n",
      "  0.02484583 -0.05370956 -0.09512627  0.05930666  0.05965794  0.10664749\n",
      "  0.0578894   0.06471135  0.0092743  -0.06704719  0.10074015  0.04975213\n",
      " -0.03799459  0.01048172  0.04314333  0.13901055 -0.04239708  0.02631451\n",
      "  0.06633118  0.00252163]\n"
     ]
    }
   ],
   "source": [
    "v = model['安徽工业大学']\n",
    "print(v.shape)\n",
    "print(type(v[0]))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "[-0.00741409 -0.09131071  0.05083036 -0.04319877 -0.02532532  0.00266612\n",
      "  0.00615757  0.04831969  0.0793904  -0.02619914 -0.02589273  0.08999024\n",
      " -0.07087526 -0.03282047 -0.06789108 -0.00793395 -0.07140415  0.00347837\n",
      "  0.00112126 -0.01099633 -0.05703546 -0.06683233  0.00785789  0.04541919\n",
      "  0.00940179 -0.0959845  -0.01589643  0.0202605   0.02683976  0.20117304\n",
      "  0.01861057 -0.07905024 -0.05859815  0.2854236  -0.05189861 -0.07470401\n",
      " -0.01923194  0.10207884 -0.05151923 -0.067327   -0.05337382 -0.05632971\n",
      " -0.00216718  0.08146963  0.02686448 -0.05758338  0.01312144 -0.00799029\n",
      "  0.00268229 -0.05050042  0.13428317  0.02066507  0.02833731  0.0036809\n",
      "  0.12844509 -0.1307342  -0.06585654  0.12269804 -0.08318231  0.00231075\n",
      " -0.03047573 -0.01288016  0.08632147 -0.05644405 -0.05607536 -0.02531487\n",
      "  0.07175215 -0.04911696 -0.01090006  0.12970683 -0.09437403  0.07975813\n",
      "  0.05520441  0.06935226  0.03716362 -0.05611055  0.07835138  0.05934883\n",
      " -0.10233817  0.09836157  0.08353174 -0.01351841 -0.06689366 -0.06000537\n",
      " -0.04325201 -0.12591255 -0.10106288  0.07204929 -0.09132069 -0.0062719\n",
      "  0.03574641  0.04613041  0.05333864 -0.0331554  -0.02339918  0.06271096\n",
      " -0.03978292  0.15184116  0.04497373 -0.01913947 -0.02384892  0.04118776\n",
      "  0.06946018 -0.03182139  0.03016932  0.12609178  0.07430418 -0.06698969\n",
      " -0.0014619   0.09025148 -0.10029414 -0.02566358  0.01606283 -0.02889997\n",
      " -0.1742679  -0.05112297  0.05743672  0.05185059 -0.04741569  0.00613665\n",
      "  0.08788273 -0.0405664  -0.01980101 -0.09073687 -0.01337008 -0.08679165\n",
      " -0.0988396   0.07571378 -0.00065988  0.00943555  0.04807153 -0.07034612\n",
      " -0.02065295  0.03464654  0.00066059  0.0004766  -0.10305724 -0.0925444\n",
      " -0.05240326  0.06311649 -0.05232316 -0.05637963 -0.01271543  0.0144072\n",
      "  0.15400074  0.06865412 -0.00051012  0.12473067  0.05646235 -0.07828506\n",
      " -0.16224633 -0.00166324 -0.06016678 -0.01981456  0.01363797  0.06882812\n",
      "  0.01378274  0.05542856  0.10708614 -0.03481673  0.1093049  -0.03313686\n",
      " -0.0751944   0.10910428  0.06513652  0.0096754  -0.03531948  0.04530272\n",
      " -0.03325143 -0.06188374 -0.02167676 -0.0265305  -0.00471825 -0.0575104\n",
      " -0.10471097 -0.04597138 -0.03861862 -0.02746802  0.01212925  0.0666512\n",
      "  0.03826016 -0.10844939 -0.15900186  0.06575481  0.00497545  0.11925532\n",
      "  0.02372056  0.09096698 -0.06223863 -0.12768038  0.11699948  0.07052273\n",
      "  0.03079283 -0.05138516  0.04373598  0.08698705 -0.03001386  0.08095998\n",
      "  0.06482156  0.04201023]\n",
      "[ 0.01320894 -0.13500237  0.05160722 -0.04799487 -0.01367943 -0.01142062\n",
      "  0.00603025  0.03666959  0.03775234 -0.03846526 -0.02234555  0.06374595\n",
      " -0.05690923 -0.02174244 -0.06261343 -0.00153151 -0.11910446 -0.0053021\n",
      " -0.00575327 -0.00784195 -0.07942477 -0.05802678  0.01576889  0.06275186\n",
      " -0.05068474 -0.08378616 -0.0209092   0.04386358  0.05843877  0.1612353\n",
      "  0.07722715 -0.09065557 -0.06228825  0.23230782 -0.05596186 -0.06227121\n",
      " -0.00432094  0.08354117 -0.06204458 -0.07340876 -0.07151361 -0.05239959\n",
      "  0.00291642  0.09765003  0.01279576 -0.05642449 -0.01528941 -0.01539544\n",
      " -0.02068562 -0.03132536  0.10637647  0.05059391  0.05496291 -0.0664221\n",
      "  0.09514629 -0.04726886 -0.06408745  0.13591322 -0.05991104  0.01128029\n",
      " -0.04468643  0.0035691   0.10321276 -0.04595972 -0.07458746 -0.0264206\n",
      "  0.01498292  0.0094169  -0.00032822  0.11457586 -0.10077588  0.06776375\n",
      "  0.05680474  0.10068029 -0.00928963 -0.00871464  0.06358088  0.09636106\n",
      " -0.09332885  0.06178718  0.04023155  0.00349149 -0.06631145 -0.03192855\n",
      " -0.03407121 -0.10564837 -0.115433    0.07793033 -0.0702596  -0.02748477\n",
      "  0.00569234  0.07533522  0.01884648 -0.03770022 -0.03598894  0.05748574\n",
      " -0.02846275  0.11295643  0.023734   -0.04395443 -0.00512127 -0.01103254\n",
      "  0.10854474 -0.03020211  0.03807094  0.07561366  0.06466651 -0.06721504\n",
      "  0.02339941  0.05662611 -0.09148291 -0.0530626  -0.02607063 -0.06159972\n",
      " -0.14618531  0.01103835  0.06640956  0.04939657 -0.07612459 -0.02779971\n",
      "  0.0315383  -0.01201166  0.02145947 -0.03284622 -0.03916417 -0.0711555\n",
      " -0.05908069  0.09247179 -0.00584882  0.00245497  0.04227953 -0.09987757\n",
      "  0.01610619  0.00026276  0.01317665 -0.0034721  -0.02492914 -0.09238432\n",
      " -0.08214287  0.06419393 -0.03335423 -0.04444968  0.00986585  0.01421421\n",
      "  0.17024513  0.05435393  0.00176701  0.08551566  0.08114296 -0.06551518\n",
      " -0.09846722  0.00906779 -0.07045542 -0.05311438  0.01906406  0.04931702\n",
      "  0.04385662  0.06461918  0.08712635  0.02357421  0.08881639 -0.01274229\n",
      " -0.09201902  0.1305753   0.06123825  0.02334746 -0.07106623  0.09083238\n",
      " -0.00472398 -0.07561886 -0.01474086 -0.01468107 -0.05407805 -0.05392374\n",
      " -0.10477576 -0.07399687 -0.03584367 -0.01949815  0.01824206  0.03451658\n",
      "  0.031553   -0.08107948 -0.12706406  0.06253073  0.03231669  0.11295141\n",
      "  0.04080498  0.07783917 -0.02648217 -0.09736378  0.10886981  0.06013743\n",
      " -0.00360088 -0.02045172  0.04343966  0.1129988  -0.03620547  0.05363724\n",
      "  0.06557637  0.02226593]\n"
     ]
    }
   ],
   "source": [
    "v1 = model['职业技术学院']\n",
    "print(v1.shape)\n",
    "print(v1)\n",
    "\n",
    "v2 = (v + v1) / 2\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_cosine_similarity(a, b):\n",
    "    vector_a = np.mat(a)\n",
    "    vector_b = np.mat(b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8541409969329834\n",
      "0.708282\n",
      "0.9620987381219261\n",
      "0.9620987703686315\n"
     ]
    }
   ],
   "source": [
    "sim_v_v1 = calculate_cosine_similarity(v, v1)\n",
    "sim_model = model.similarity('安徽工业大学', '职业技术学院')\n",
    "print(sim_v_v1)\n",
    "print(sim_model)\n",
    "\n",
    "sim_v_v2 = calculate_cosine_similarity(v, v2)\n",
    "sim_v1_v2 = calculate_cosine_similarity(v1, v2)\n",
    "print(sim_v_v2)\n",
    "print(sim_v1_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check whether a word is in model\n",
    "This dataset may not cover all the words we query. And due to the simplificatio of the dataset, I probably can not find the query word. I should check the existence first in order to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not IN Vocabulary\n"
     ]
    }
   ],
   "source": [
    "if 'lyc' in model.vocab:\n",
    "    print('In Vocabulary')\n",
    "else:\n",
    "    print('Not IN Vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
