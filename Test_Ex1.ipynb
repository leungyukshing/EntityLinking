{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "I try to process a specific text here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '__团队成员#1__先生是公司创始人,也是中国最有影响力的商界领袖之一。1982年,__团队成员#1__先生于华南理工大学毕业,进入TCL的前身-TTK家庭电器有限公司。1985年,他担任新成立的TCL通讯设备公司总经理,创立了TCL品牌。2003年,__团队成员#1__担任TCL集团股份有限公司董事长兼CEO,随后TCL集团整体上市。在他的领导下,2004年TCL一举收购了法国汤姆逊全球彩电业务与阿尔卡特全球手机业务。目前TCL集团已经成为拥有6万名员工,业务遍及全球80多个国家和地区。2013年,TCL集团营业总收入超过855亿元,液晶电视全球销量1766万台,实际产量全球第三,品牌销售全球第三;TCL手机全球销量5520万台,行业排名全球第五。2012年__团队成员#1__被新华网评为“最具社会责任感企业家”;2011年荣获《中国企业家》“最具影响力的25位企业领袖”终身成就奖;2009年被评为“CCTV中国经济年度人物十年商业领袖”;2008年获改革开放30年经济人物称号;2004年被评为Fortune杂志“亚洲年度经济人物”、TIME杂志和CNN全球最具影响力的25名商界人士,同年法国总统希拉克向__团队成员#1__先生颁发了法国国家荣誉勋章。__团队成员#1__是中共第十六大代表,第十届、第十一届、第十二届全国人大代表。__团队成员#1__担任的社会职务包括:中国电子视像行业协会会长;中国国际商会副会长;全国工商联执行委员、广东省工商联(总商会)副主席。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__团队成员#2__先生,现任TCL集团股份有限公司执行董事、总裁(COO)。1963年4月出生,博士,毕业于西安交通大学。薄先生1988年至1993年间任陕西财经学院贸易经济系副主任,1993年5月至2000年5月间任深圳航空公司总会计师,是深圳航空公司创始人之一。薄先生2000年5月至2004年4月间任TCL信息产业集团副总裁、财务总监,2004年4月至2005年1月间任TCL集团部品事业本部副总裁,2005年1月至2005年10月间任TCL集团股份有限公司人力资源部部长、总裁办主任,2005年10月至2006年11月间任TCL集团股份有限公司控股子公司TTE Corporation执行副总裁,2006年6月至2007年9月间任TCL集团股份有限公司人力资源总监,2006年8月至2007年10月间任TCL集团股份有限公司副总裁,2007年10月至2008年6月间任高级副总裁,2008年6月至2011年6月,任TCL集团股份有限公司首席运营官,2011年6月至今任TCL集团股份有限公司总裁(COO),2012年12月24日起任深圳市华星光电技术有限公司CEO。__团队成员#2__先生现兼任TCL多媒体科技控股有限公司执行董事、深圳市华星光电技术有限公司董事、翰林汇信息产业股份有限公司董事长、TCL教育网有限公司董事长、电大在线远程教育技术有限公司副董事长。__团队成员#2__先生于二零一四年十月二十三日调任为TCL多媒体科技控股有限公司之执行董事，并获委任为策略执行委员会主席。__团队成员#2__先生获委任为TCL多媒体科技控股有限公司首席执行官,自二零一五年六月二十五日起生效。\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import chardet\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text\n",
    "+ remove punctuations\n",
    "+ remove stopwords\n",
    "+ to lower letter for regconition later\n",
    "+ generate N-grams to link entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(seglist):\n",
    "    stopwords = {}\n",
    "    fstop = open('data/stopwords_cn.txt', 'r', encoding='utf-8', errors='ignore')\n",
    "    for w in fstop:\n",
    "        stopwords[w.strip()] = w.strip()\n",
    "\n",
    "    fstop.close()\n",
    "    stopwords[' '] = ' '\n",
    "    \n",
    "    segListSanitized = []\n",
    "\n",
    "    for word in seglist:\n",
    "        if word not in stopwords:\n",
    "            segListSanitized.append(word)\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # remove punctuations\n",
    "    text = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", text)\n",
    "    text = text.lower()\n",
    "    # seperate words\n",
    "    words = jieba.cut(text, cut_all=False)\n",
    "    seglist = list(words)\n",
    "    # remove stopwords\n",
    "    segListSanitized = removeStopWords(seglist)\n",
    "    print(f'Before sanitize, len: {len(seglist)}. After sanitize, len: {len(segListSanitized)}')\n",
    "\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(wordList, n):\n",
    "    '''\n",
    "    This function only generete N-Grams\n",
    "    '''\n",
    "    output = set()\n",
    "    for i in range (len(wordList) - n + 1):\n",
    "        n_gram_temp = \"\".join(wordList[i:i+n])\n",
    "        output.add(n_gram_temp)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNgrams(wordList, n):\n",
    "    '''\n",
    "    This function genereates [1, N]-Grams\n",
    "    '''\n",
    "    result = set()\n",
    "    for i in range(n):\n",
    "        temp = getNgrams(wordList, i+1)\n",
    "        result = result | temp\n",
    "        print(f'i = {i}, len: {len(temp)}')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 330. After sanitize, len: 264\n",
      "i = 0, len: 108\n",
      "i = 1, len: 172\n",
      "i = 2, len: 209\n",
      "489\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text)\n",
    "output = generateNgrams(segListSanitized, 3)\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Using Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('./test_50.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_cosine_similarity(a, b):\n",
    "    vector_a = np.mat(a)\n",
    "    vector_b = np.mat(b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEmbeddings(name):\n",
    "    words = jieba.cut(name, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    for word in word_list:\n",
    "        if word in model.vocab:\n",
    "            v += model[word]\n",
    "    \n",
    "    v /= len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entity_list(df, model):\n",
    "    '''\n",
    "    df: dafaframe\n",
    "    model: word embedding model\n",
    "    '''\n",
    "    \n",
    "    df['embeddings'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        # df.loc[index, 'embeddings'] = z\n",
    "        name = row['name']\n",
    "        if isinstance(name, float):\n",
    "            continue\n",
    "        name = name.lower()\n",
    "        if name in model.vocab:\n",
    "            vec = model[name]\n",
    "        else:\n",
    "            vec = generateEmbeddings(name)\n",
    "        df.set_value(index, 'embeddings', vec)\n",
    "\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path0 = 'data/chinese_university_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  rank    name\n",
      "0    1    北京大学\n",
      "1    2  中国人民大学\n",
      "2    3    清华大学\n",
      "3    4  北京交通大学\n",
      "4    5  北京工业大学\n"
     ]
    }
   ],
   "source": [
    "school_df = pd.read_csv(path0, header=None, delimiter=\",\", skiprows=4, names=[\"rank\", \"name\", \"code\", \"department\", \"city\", \"level\", \"notes\"])\n",
    "school_df = pd.DataFrame(school_df, columns=['rank', 'name'])\n",
    "print(school_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkSchool(output, school_df, model, threshold):\n",
    "    for term in output:\n",
    "        if term in model.vocab:\n",
    "            term_vec = model[term]\n",
    "            school_candidate = dict()\n",
    "            for index, row in school_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name_vec = row['embeddings']\n",
    "                sim = calculate_cosine_similarity(term_vec, name_vec)\n",
    "                if (sim > threshold):\n",
    "                    school_candidate[name] = sim\n",
    "            if len(school_candidate) == 0:\n",
    "                continue\n",
    "            school_candidate = sorted(school_candidate.items(), key=lambda item:item[1], reverse=True)\n",
    "            print(f'university entity found: {term}->{school_candidate[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  rank    name                                         embeddings\n",
      "0    1    北京大学  [0.037607472, 0.039331738, 0.024360932, -0.023...\n",
      "1    2  中国人民大学  [0.029720008, -0.04914518, -0.06820664, 0.0211...\n",
      "2    3    清华大学  [0.015153781, 0.046060637, -0.0013895197, -0.0...\n",
      "3    4  北京交通大学  [0.019046584, -0.0035929743, -0.022275247, -0....\n",
      "4    5  北京工业大学  [0.01881563, -0.007572121, -0.009649365, -0.00...\n"
     ]
    }
   ],
   "source": [
    "school_df = preprocess_entity_list(school_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university entity found: 华南理工大学->华南理工大学\n"
     ]
    }
   ],
   "source": [
    "linkSchool(output, school_df, model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university entity found: 西安交通大学->西安交通大学\n",
      "university entity found: 财经学院->宁波财经学院\n"
     ]
    }
   ],
   "source": [
    "linkSchool(output, school_df, model, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "path4 = 'data/company_list_ch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank             name\n",
      "0     1   中国石油化工集团有限公司\\n\n",
      "1     2  中国石油天然气集团有限公司\\n\n",
      "2     3       国家电网有限公司\\n\n",
      "3     4     中国建筑股份有限公司\\n\n",
      "4     5   中国工商银行股份有限公司\\n\n"
     ]
    }
   ],
   "source": [
    "company_ch_df = pd.read_csv(path4, header=None, delimiter=\",\", skiprows=2, names=['rank', 'name', 'Location', 'Income'])\n",
    "company_ch_df = pd.DataFrame(company_ch_df, columns=['rank', 'name'])\n",
    "print(company_ch_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IDF(df):\n",
    "    company_num = 0\n",
    "    m = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        name = row['name']\n",
    "        name = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", name)\n",
    "        name = name.lower()\n",
    "        if isinstance(name, float) or name == \" \":\n",
    "            continue\n",
    "        company_num += 1\n",
    "        words = jieba.cut(name, cut_all=False)\n",
    "        word_list = list(words)\n",
    "        for word in word_list:\n",
    "            if word in m.keys():\n",
    "                m[word] +=1\n",
    "            else:\n",
    "                m[word] = 1\n",
    "                \n",
    "    print(f'company number: {company_num}, dict size: {len(m)}')\n",
    "    # print(m)\n",
    "    \n",
    "    idf = dict()\n",
    "    \n",
    "    for (k, v) in m.items():\n",
    "        idf[k] = math.log(((1+company_num) / v), 10)\n",
    "    \n",
    "    # Normalize min-max\n",
    "    v = idf.values()\n",
    "    max_value = max(v)\n",
    "    min_value = min(v)\n",
    "    denom = max_value - min_value\n",
    "    for (k, v) in idf.items():\n",
    "        idf[k] = (idf[k] - min_value) / denom\n",
    "\n",
    "    print(idf)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company number: 500, dict size: 622\n",
      "{'中国石油化工集团': 1.0, '有限公司': 0.05513610495796486, ' ': 0.0, '中国石油天然气集团': 1.0, '国家电网': 1.0, '中国': 0.3738793760288948, '建筑': 0.8283487347101395, '股份': 0.3551611915126718, '中国工商银行': 1.0, '平安保险': 1.0, '集团': 0.13730643414831753, '中国建设银行': 1.0, '中国农业银行': 1.0, '上海': 0.5876638788101248, '汽车': 0.8283487347101395, '集团股份': 0.46346108202223235, '中国银行': 1.0, '人寿保险': 0.7485354415526261, '公司': 0.36291040184728496, '铁路': 0.8283487347101395, '工程': 1.0, '中国移动通信集团': 1.0, '铁道': 1.0, '华为': 1.0, '投资': 0.4358167708877228, '控股': 0.4123361211898751, '海洋': 1.0, '石油': 0.8917001094904394, '国家开发银行': 1.0, '华润': 1.0, '苏宁': 1.0, '控股集团': 0.4052329109729049, '东风汽车': 1.0, '第一': 1.0, '汽车集团': 0.7485354415526261, '交通': 0.7200488442005789, '建设': 0.5876638788101248, '中化': 1.0, '集团公司': 0.7834002189808787, '太平洋': 1.0, '中国邮政': 1.0, '国家': 0.8283487347101395, '能源': 0.5399499154015097, '有限责任': 0.3856769565408303, '南方电网': 1.0, '五矿': 1.0, '正威': 1.0, '国际': 0.6253439344762688, '人民保险': 1.0, '北京': 0.5768841762627654, '中粮': 1.0, '中信集团': 1.0, '恒大': 1.0, '京东': 1.0, '世纪': 1.0, '贸易': 1.0, '中国兵器工业集团': 1.0, '中国电信集团': 1.0, '化工集团': 0.7485354415526261, '航空工业': 1.0, '宝武': 1.0, '钢铁集团': 0.5876638788101248, '交通银行': 1.0, '电力': 0.7834002189808787, '医药集团': 0.7485354415526261, '碧桂园': 1.0, '阿里巴巴': 1.0, '恒力': 1.0, '招商银行': 1.0, '广州': 0.6566974694202788, '工业': 0.7834002189808787, '太平洋保险': 1.0, '绿地': 1.0, '中国建材': 1.0, '山东': 0.5319356605335049, '联想集团': 1.0, '兴业银行': 1.0, '河钢': 1.0, '上海浦东发展银行': 1.0, '国美': 1.0, '浙江': 0.6566974694202788, '吉利': 1.0, '中国民生银行': 1.0, '腾讯': 1.0, '保利': 1.0, '船舶': 1.0, '重工': 0.8917001094904394, '招商局': 1.0, '物产': 0.8917001094904394, '中': 0.6751003284713183, '大': 0.8917001094904394, '机械': 1.0, '铝业': 1.0, '万科': 1.0, '企业': 0.8917001094904394, '陕西': 0.7200488442005789, '延长': 1.0, '联合': 0.8283487347101395, '网络通信': 1.0, '魏桥': 1.0, '创业': 0.8917001094904394, '厦门': 0.8283487347101395, '建发': 1.0, '远洋': 1.0, '海运': 0.8917001094904394, '煤业': 0.8917001094904394, '航空': 0.8283487347101395, '油料': 1.0, '华能': 1.0, '光大': 1.0, '国贸': 1.0, '雪松': 1.0, '海尔集团': 1.0, '美的': 1.0, '兖矿': 1.0, '中国航天': 1.0, '科工': 1.0, '中国航天科技集团': 1.0, '象屿': 1.0, '江苏': 0.5876638788101248, '沙钢': 1.0, '冀中': 1.0, '潍柴': 1.0, '江西': 1.0, '铜业': 1.0, '中车': 1.0, '青山': 1.0, '能源建设': 1.0, '兵器': 1.0, '装备': 0.8283487347101395, '中南': 1.0, '阳光': 0.8917001094904394, '龙净': 1.0, '金川': 1.0, '电子科技': 1.0, '电子': 0.7834002189808787, '信息产业': 1.0, '鞍钢': 1.0, '华电': 1.0, '首钢': 1.0, '珠海': 0.8917001094904394, '格力电器': 1.0, '大唐': 1.0, '新疆': 0.7834002189808787, '广汇': 1.0, '实业': 0.8283487347101395, '安徽': 0.8283487347101395, '海螺集团': 1.0, '华夏': 1.0, '太平': 1.0, '保险': 0.7834002189808787, '大连': 1.0, '万达': 0.8917001094904394, '铜陵': 1.0, '有色金属': 0.8917001094904394, '山西': 0.7485354415526261, '潞安': 1.0, '矿业': 0.8917001094904394, '焦煤': 1.0, '大同': 1.0, '煤矿': 1.0, '小米': 1.0, '阳泉': 1.0, '海亮': 1.0, '新兴': 1.0, '际华': 1.0, '晋城': 1.0, '无烟煤': 1.0, '矿业集团': 0.7834002189808787, '建工': 0.6751003284713183, '河南': 0.8283487347101395, '通用': 1.0, '技术': 0.8283487347101395, '泰康': 1.0, '光明': 1.0, '食品': 0.8283487347101395, '东浩兰生': 1.0, '新华': 0.8283487347101395, '华晨': 1.0, '煤': 1.0, '万洲': 1.0, '恒逸': 1.0, '南方': 1.0, '盛虹': 1.0, '华夏银行': 1.0, '广西': 0.7200488442005789, '浙江省': 0.7485354415526261, '国际航空': 1.0, '北大方正集团': 1.0, '天能': 1.0, '电池': 1.0, '新': 0.8917001094904394, '希望': 1.0, '中国林业': 1.0, '比亚迪': 1.0, '荣盛': 0.8917001094904394, '中国东方航空': 1.0, '首农': 1.0, '海信集团': 1.0, '平煤': 1.0, '神马': 1.0, '天': 0.8283487347101395, '重庆市': 0.8917001094904394, '金科': 1.0, '南通': 0.7834002189808787, '三建': 1.0, '四川长虹': 1.0, '开发': 0.8917001094904394, '湖南': 0.8283487347101395, '华菱': 1.0, '超威': 1.0, '建龙': 1.0, '海澜': 1.0, '南京': 1.0, '银行': 0.7834002189808787, '云南省': 0.7834002189808787, '黑龙江': 1.0, '北大荒': 1.0, '农垦': 1.0, '总公司': 0.8283487347101395, '龙湖': 1.0, '电气': 1.0, 'tcl': 1.0, '万向集团': 1.0, '协鑫': 1.0, '东方': 1.0, '有色': 0.8917001094904394, '兴合': 1.0, '华侨城集团': 1.0, '重型汽车': 1.0, '东岭': 1.0, '复星': 1.0, '南山': 1.0, '西安': 1.0, '迈科': 1.0, '金属': 0.8917001094904394, '河北': 0.7200488442005789, '津西': 1.0, '华融': 1.0, '资产': 0.7834002189808787, '管理': 0.8283487347101395, '信': 1.0, '达': 1.0, '紫金': 1.0, '黄金': 0.8917001094904394, '金隅': 1.0, '均': 0.8917001094904394, '和': 1.0, '晋能': 1.0, '杭州': 0.8283487347101395, '亨通': 1.0, '东明': 1.0, '石化集团': 0.8283487347101395, '浪潮集团': 1.0, '江铃': 1.0, '泰': 1.0, '福晟': 1.0, '长城汽车': 1.0, '广核': 1.0, '甘肃省': 0.8917001094904394, '公路': 1.0, '旅游': 0.8917001094904394, '富德': 1.0, '生命': 1.0, '酒泉': 1.0, '钢铁': 0.6253439344762688, '钢联': 1.0, '电子商务': 1.0, '日照': 1.0, '汽轮': 1.0, '动力': 1.0, '新华联': 1.0, '集装箱': 1.0, '四川省': 0.7485354415526261, '宜宾': 1.0, '五粮液': 1.0, '无锡': 1.0, '产业': 0.7834002189808787, '发展': 0.8283487347101395, '马钢': 1.0, '悦达': 1.0, '深圳': 0.8283487347101395, '顺': 1.0, '丰泰': 1.0, '森': 1.0, '智力': 1.0, '合作': 1.0, '敬业': 1.0, '上海银行': 1.0, '柳州': 1.0, '锦江': 1.0, '雅戈尔集团': 1.0, '北京外企服务集团': 1.0, '九州': 1.0, '通': 1.0, '包头': 1.0, '化学工程': 1.0, '江阴': 1.0, '澄星': 1.0, '实业集团': 0.7200488442005789, '奥克斯': 1.0, '利华益': 1.0, '福': 1.0, '传化': 1.0, '腾邦': 1.0, '宁波': 0.7834002189808787, '金田': 1.0, '卓尔': 1.0, '百度': 1.0, '网络': 1.0, '神州数码': 1.0, '内蒙古': 0.8283487347101395, '广厦': 1.0, '中融': 1.0, '新大': 1.0, '扬子江': 0.8917001094904394, '药业': 1.0, '伊利': 1.0, '唯品': 1.0, '会': 1.0, '宁夏': 1.0, '天元': 0.8917001094904394, '锰业': 1.0, '太原': 1.0, '正邦': 1.0, '贵州': 1.0, '茅台酒': 1.0, '弘阳': 1.0, '开滦': 1.0, '北京城建集团': 1.0, '冶金': 1.0, '首都': 0.8283487347101395, '华泰': 1.0, '深圳市': 0.7834002189808787, '高速': 1.0, '通威': 1.0, '永辉': 1.0, '超市': 1.0, '正泰': 1.0, '广州市': 1.0, '怡亚通': 1.0, '供应链': 1.0, '永达': 1.0, '福建省': 0.8917001094904394, '北部湾': 0.8917001094904394, '港务': 0.8917001094904394, '天津': 0.8283487347101395, '荣程祥泰': 1.0, '奇瑞': 1.0, '三房': 1.0, '巷': 1.0, '网易公司': 1.0, '北京住总集团': 1.0, '云南': 1.0, '锡业': 1.0, '红豆集团': 1.0, '远大': 1.0, '互诚': 1.0, '信息技术': 1.0, '二建': 1.0, '前': 1.0, '海': 1.0, '徐州': 0.8917001094904394, '工程机械': 1.0, '三一': 1.0, '江': 1.0, '西方': 1.0, '云天化': 1.0, '本钢': 1.0, '物资': 1.0, '金鼎': 1.0, '淮北': 1.0, '百联': 1.0, '四建': 1.0, '海科': 1.0, '白银': 1.0, '青建': 1.0, '新奥': 1.0, '万华': 1.0, '化学': 1.0, '华谊': 1.0, '双胞胎': 1.0, '新余': 1.0, '盘锦': 1.0, '北方': 1.0, '沥青': 1.0, '燃料': 1.0, '天津泰达': 1.0, '武安市': 0.8283487347101395, '文安': 1.0, '如意': 1.0, '时尚': 1.0, '普阳': 1.0, '冀南': 1.0, '国际贸易': 1.0, '广东省': 0.7200488442005789, '广晟': 1.0, '经营': 1.0, '中基': 1.0, '国泰': 1.0, '玖': 1.0, '龙': 1.0, '纸业': 0.8917001094904394, '温氏': 1.0, '三钢': 1.0, '爱施德': 1.0, '昆明': 1.0, '四川': 0.8283487347101395, '华西': 0.8917001094904394, '隆鑫': 1.0, '德力西': 1.0, '广新': 1.0, '胜': 1.0, '蓝润': 1.0, '伊泰': 1.0, '煤炭': 1.0, '进出口': 1.0, '杭州市': 1.0, '江苏省': 1.0, '苏中': 1.0, '重庆': 0.6751003284713183, '商社': 1.0, '裕华': 1.0, '科技': 0.7485354415526261, '特变': 1.0, '电工': 1.0, '山': 1.0, '东京': 1.0, '博': 1.0, '渤海': 0.8917001094904394, '华发': 1.0, '友发': 1.0, '钢管': 1.0, '川威': 1.0, '金诚': 1.0, '河北省': 1.0, '物流': 1.0, '稻': 1.0, '花香': 1.0, '永锋': 1.0, '招金': 1.0, '东旭': 1.0, '信息': 1.0, '通信': 0.8917001094904394, '安阳': 1.0, '江淮': 1.0, '旭阳': 1.0, '海王': 1.0, '辽宁': 1.0, '嘉晨': 1.0, '城建': 1.0, '东华': 1.0, '建筑工程': 1.0, '龙光': 1.0, '智能': 1.0, '晶科': 1.0, '长江': 1.0, '博长': 1.0, '新凤祥': 1.0, '船业': 1.0, '北京建工集团': 1.0, '化医': 1.0, '德胜': 1.0, '钒': 1.0, '钛': 1.0, '盛京': 1.0, '唐': 1.0, '山港': 1.0, '陆': 1.0, '杉杉': 1.0, '农村': 0.8283487347101395, '商业银行': 0.8283487347101395, '山河': 1.0, '明芳': 1.0, '机电': 1.0, '中运富通': 1.0, '红狮': 1.0, '新金': 1.0, '西王': 1.0, '太极集团': 1.0, '威高': 1.0, '越秀': 1.0, '轻工': 1.0, '工贸': 1.0, '六建': 1.0, '小康': 1.0, '淮河': 1.0, '江西省': 1.0, '金澳': 1.0, '湖北': 1.0, '化工': 0.8917001094904394, '华勤': 1.0, '橡胶': 1.0, '广物': 1.0, '老凤祥': 1.0, '郑州': 1.0, '宇通': 1.0, '成都': 1.0, '兴城': 1.0, '中华': 1.0, '金浦': 1.0, '人民': 1.0, '电器集团': 1.0, '欧菲光': 1.0, '中科': 1.0, '富冶': 1.0, '通鼎': 1.0, '福佳': 1.0, '前程': 1.0, '恒源': 1.0, '石油化工': 1.0, '新增': 1.0, '鼎': 1.0, '申能': 1.0, '广东': 0.8917001094904394, '海大': 1.0, '环嘉': 1.0, '石横': 1.0, '特钢': 1.0, '科达': 1.0, '成': 1.0, '物美': 1.0, '科伦': 1.0, '玉皇': 1.0, '金岭': 1.0, '森源': 1.0, '圣丰': 1.0, '重庆力帆': 1.0, '汇丰': 1.0, '天音': 1.0, '城市': 1.0, '富通': 1.0, '福建': 0.8917001094904394, '永荣': 1.0, '创新': 1.0, '恒申': 1.0, '通州': 1.0, '建总': 1.0, '大汉': 1.0, '中利': 1.0, '三河': 1.0, '汇福': 1.0, '粮油': 1.0, '仪电': 1.0, '步步高': 1.0, '汇鸿': 1.0, '创维集团': 1.0, '华宏': 1.0, '双良': 1.0, '沂州': 1.0, '万宝': 1.0, '西部': 1.0, '大地': 1.0, '财产保险': 1.0, '阳光集团': 1.0, '滨化': 1.0, '法尔': 1.0, '胜泓': 1.0, '昇': 1.0, '宜昌': 1.0, '兴发': 1.0, '山东泰山': 1.0, '天瑞': 1.0, '武汉': 0.8917001094904394, '金融': 1.0, '龙信': 1.0, '远东': 1.0, '富邦': 1.0, '红太阳集团': 1.0, '豫光金': 1.0, '铅': 1.0, '商联': 1.0, '齐鲁': 1.0, '维维集团': 1.0, '市政': 0.8917001094904394, '路桥': 1.0, '新疆生产建设兵团': 1.0, '建设工程': 1.0, '金雅福': 1.0, '江南': 1.0, '卧龙': 1.0, '博汇': 1.0, '玉柴': 1.0, '机器': 1.0, '宝业': 1.0, '天业': 1.0, '立讯': 1.0, '精密': 1.0, '安徽省': 1.0, '皖北': 1.0, '煤电': 1.0, '矿务': 1.0, '国资': 1.0, '名': 1.0, '创优': 1.0, '品': 1.0, '九羊': 1.0, '清源': 1.0, '锦': 1.0, '轻纺': 1.0, '龙盛': 1.0, '晶龙': 1.0, '中农': 1.0, '网': 1.0, '南昌': 1.0, '公用': 1.0, '波司登': 1.0, '融信': 1.0, '远景': 1.0, '万基': 1.0, '瑞康': 1.0, '澳洋': 1.0, '岚桥': 1.0, '金融街': 1.0, '金': 1.0, '东': 1.0, '香江': 1.0, '华宇': 1.0, '新凤鸣': 1.0, '富海': 1.0, '昆仑': 1.0, '中国东方电气集团': 1.0}\n"
     ]
    }
   ],
   "source": [
    "idf = calculate_IDF(company_ch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCompanyEmbeddings(name, idf):\n",
    "    words = jieba.cut(name, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    for word in word_list:\n",
    "        if word in model.vocab:\n",
    "            # emb(term) * IDF\n",
    "            # print(f'word: {word}')\n",
    "            # print(idf[word])\n",
    "            v += model[word] * idf[word]\n",
    "    \n",
    "    v /= len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_company_entity_list(df, model, idf):\n",
    "    '''\n",
    "    df: dafaframe\n",
    "    model: word embedding model\n",
    "    '''\n",
    "    \n",
    "    df['embeddings'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        name = row['name']\n",
    "        name = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", name)\n",
    "        name = name.lower()\n",
    "        if isinstance(name, float):\n",
    "            continue\n",
    "        if name in model.vocab:\n",
    "            vec = model[name]\n",
    "        else:\n",
    "            vec = generateCompanyEmbeddings(name, idf)\n",
    "        df.set_value(index, 'embeddings', vec)\n",
    "\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkCompany(output, company_df, model, threshold):\n",
    "    for term in output:\n",
    "        if len(term) <= 1:\n",
    "            continue\n",
    "        if term in model.vocab:\n",
    "            term_vec = model[term]\n",
    "            company_candidate = dict()\n",
    "            for index, row in company_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name_vec = row['embeddings']\n",
    "                sim = calculate_cosine_similarity(term_vec, name_vec)\n",
    "                if (sim > threshold):\n",
    "                    company_candidate[name] = sim\n",
    "            if len(company_candidate) == 0:\n",
    "                continue\n",
    "            company_candidate = sorted(company_candidate.items(), key=lambda item:item[1], reverse=True)\n",
    "            print(f'company entity found: {term}->{company_candidate[0][0]}, sim = {company_candidate[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank             name                                         embeddings\n",
      "0     1   中国石油化工集团有限公司\\n  [0.00020857858937233686, 0.0002797483908943832...\n",
      "1     2  中国石油天然气集团有限公司\\n  [0.0004169972753152251, -7.988460594788194e-05...\n",
      "2     3       国家电网有限公司\\n  [0.00040219956543296575, -0.000430932913441211...\n",
      "3     4     中国建筑股份有限公司\\n  [0.00030216909712180493, -0.000533461889717727...\n",
      "4     5   中国工商银行股份有限公司\\n  [0.00018973188241943717, -0.000447552979458123...\n"
     ]
    }
   ],
   "source": [
    "company_ch_df = preprocess_company_entity_list(company_ch_df, model, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company entity found: tcl->TCL集团股份有限公司\n",
      ", sim = 0.9610930736775853\n",
      "company entity found: 有限公司->中运富通控股集团有限公司\n",
      ", sim = 0.9063590600834653\n",
      "company entity found: 集团股份有限公司->中运富通控股集团有限公司\n",
      ", sim = 0.9037290995606039\n",
      "company entity found: 企业->万科企业股份有限公司\n",
      ", sim = 0.9212849717105785\n",
      "company entity found: 广东省->广东省能源集团有限公司\n",
      ", sim = 0.9212187301398342\n",
      "company entity found: 国家->国家电力投资集团有限公司\n",
      ", sim = 0.9082963948292435\n"
     ]
    }
   ],
   "source": [
    "linkCompany(output, company_ch_df, model, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company entity found: 深圳->深圳金雅福控股集团有限公司\n",
      ", sim = 0.9626824059668808\n",
      "company entity found: 控股有限公司->中运富通控股集团有限公司\n",
      ", sim = 0.93357818225778\n",
      "company entity found: tcl->TCL集团股份有限公司\n",
      ", sim = 0.9610930736775853\n",
      "company entity found: 信息产业->中国电子信息产业集团有限公司\n",
      ", sim = 0.9422591406677782\n",
      "company entity found: 有限公司->中运富通控股集团有限公司\n",
      ", sim = 0.9063590600834653\n",
      "company entity found: 集团股份有限公司->中运富通控股集团有限公司\n",
      ", sim = 0.9037290995606039\n",
      "company entity found: 科技->山东创新金属科技有限公司\n",
      ", sim = 0.9151182263571489\n",
      "company entity found: 深圳市->深圳市投资控股有限公司\n",
      ", sim = 0.931279784196003\n",
      "company entity found: 控股->阿里巴巴集团控股有限公司\n",
      ", sim = 0.9032541848685627\n",
      "company entity found: 股份有限公司->中运富通控股集团有限公司\n",
      ", sim = 0.906345197516979\n",
      "company entity found: 陕西->陕西投资集团有限公司\n",
      ", sim = 0.9387841332452491\n"
     ]
    }
   ],
   "source": [
    "linkCompany(output, company_ch_df, model, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  degree\n",
      "0     本科\n",
      "1    研究生\n",
      "2     博士\n"
     ]
    }
   ],
   "source": [
    "degree = {'degree': ['本科', '研究生', '博士']}\n",
    "degree_df = pd.DataFrame(degree)\n",
    "print(degree_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_degree_entity_list(df, model):\n",
    "    '''\n",
    "    df: dafaframe\n",
    "    model: word embedding model\n",
    "    '''\n",
    "    \n",
    "    df['embeddings'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        name = row['degree']\n",
    "        vec = model[name]\n",
    "        df.set_value(index, 'embeddings', vec)\n",
    "\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  degree                                         embeddings\n",
      "0     本科  [-0.060282774, -0.077274054, 0.024572397, 0.00...\n",
      "1    研究生  [-0.032758698, -0.03760286, 0.054133926, -0.05...\n",
      "2     博士  [-0.06615932, 0.07013251, -0.006140913, -0.047...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "degree_df = preprocess_degree_entity_list(degree_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkDegree(output, degree_df, model, threshold):\n",
    "    for term in output:\n",
    "        if len(term) <= 1:\n",
    "            continue\n",
    "        if term in model.vocab:\n",
    "            term_vec = model[term]\n",
    "            company_candidate = dict()\n",
    "            for index, row in degree_df.iterrows():\n",
    "                name = row['degree']\n",
    "                name_vec = row['embeddings']\n",
    "                sim = calculate_cosine_similarity(term_vec, name_vec)\n",
    "                if (sim > threshold):\n",
    "                    company_candidate[name] = sim\n",
    "            if len(company_candidate) == 0:\n",
    "                continue\n",
    "            company_candidate = sorted(company_candidate.items(), key=lambda item:item[1], reverse=True)\n",
    "            print(f'degree entity found: {term}->{company_candidate[0][0]}, sim = {company_candidate[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree entity found: 博士->博士, sim = 1.0\n"
     ]
    }
   ],
   "source": [
    "linkDegree(output, degree_df, model, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
