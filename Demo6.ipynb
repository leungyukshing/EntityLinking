{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo6\n",
    "In this notebook, an exact match demo will be completed, acts as a comparison to the present model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import chardet\n",
    "import pandas as pd\n",
    "import prettytable as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSchool():\n",
    "    path1 = 'data/chinese_university_list.csv'\n",
    "    school_df = pd.read_csv(path1, header=None, delimiter=\",\", skiprows=4, names=[\"rank\", \"name\", \"code\", \"department\", \"city\", \"level\", \"notes\"])\n",
    "    school_df = pd.DataFrame(school_df, columns=['name'])\n",
    "    \n",
    "    path2 = 'data/all_university_list.csv'\n",
    "    school_global_df = pd.read_csv(path2, header=None, delimiter=',', skiprows=2, names=['Name_en', 'name', 'rank', 'score', 'location'])\n",
    "    school_global_df = pd.DataFrame(school_global_df, columns=['name'])\n",
    "    \n",
    "    school_df = pd.concat([school_df, school_global_df], axis=0, ignore_index=True)\n",
    "    return school_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDegree():\n",
    "    degree = {'name': ['本科', '硕士' ,'研究生', '博士']}\n",
    "    degree_df = pd.DataFrame(degree)\n",
    "    return degree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCompany():\n",
    "    path1 = 'data/company_list_ch.csv'\n",
    "    company_ch_df = pd.read_csv(path1, header=None, delimiter=\",\", skiprows=2, names=['rank', 'name', 'Location', 'Income'])\n",
    "    company_ch_df = pd.DataFrame(company_ch_df, columns=['name'])\n",
    "    path2 = 'data/member-data.csv'\n",
    "    company_df = pd.read_csv(path2, header=None, delimiter=\",\", skiprows=2, names=['name', 'No.', 'Resume', 'Position'])\n",
    "    company_df = pd.DataFrame(company_df, columns=['name'])\n",
    "    company_ch_df = pd.concat([company_ch_df, company_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    print(f'before dedup, company size: {company_ch_df.shape[0]}')\n",
    "    company_ch_df = company_ch_df.drop_duplicates(subset=['name'], keep='first')\n",
    "    print(f'after dedup, company size: {company_ch_df.shape[0]}')\n",
    "    return company_ch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPosition():\n",
    "    path5 = 'data/position.csv'\n",
    "    position_df1 = pd.read_csv(path5, header=None, delimiter=\",\", skiprows=1, names=['name'])\n",
    "    position_df1 = pd.DataFrame(position_df1)\n",
    "\n",
    "    path6 = 'data/member-data.csv'\n",
    "    position_df2 = pd.read_csv(path6, header=None, delimiter=\",\", skiprows=1, names=['Company', 'No.', 'Resume', 'name'])\n",
    "    position_df2 = pd.DataFrame(position_df2, columns=['name'])\n",
    "\n",
    "    member_position_list = []\n",
    "    # process position in member-data\n",
    "    for index, row in position_df2.iterrows():\n",
    "        position = row['name']\n",
    "        if isinstance(position, float) or position == \" \" or position.isalpha():\n",
    "            continue\n",
    "        if \"&\" in position:\n",
    "            temp1 = position.split('&')\n",
    "            member_position_list += temp1\n",
    "        elif \" \" in position:\n",
    "            temp2 = position.split( )\n",
    "            member_position_list += temp2\n",
    "        else:\n",
    "            member_position_list.append(position)\n",
    "\n",
    "    position_df3 = pd.DataFrame(member_position_list, columns=['name'])\n",
    "    position_df1 = pd.concat([position_df1, position_df3], axis=0, ignore_index=True)\n",
    "    print(f'before dedup, position size: {position_df1.shape[0]}')\n",
    "    position_df1 = position_df1.drop_duplicates(subset=['name'], keep='first')\n",
    "    print(f'after dedup, position size: {position_df1.shape[0]}')\n",
    "    # print(df1.head())\n",
    "    return position_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMember():\n",
    "    path = 'data/member-data.csv'\n",
    "    member_df = pd.read_csv(path, header=None, delimiter=\",\", skiprows=1, names=['Company', 'No.', 'Resume', 'Position'])\n",
    "    member_df = pd.DataFrame(member_df, columns=['Resume'])\n",
    "    return member_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(seglist):\n",
    "    stopwords = {}\n",
    "    fstop = open('data/stopwords_cn.txt', 'r', encoding='utf-8', errors='ignore')\n",
    "    for w in fstop:\n",
    "        stopwords[w.strip()] = w.strip()\n",
    "\n",
    "    fstop.close()\n",
    "    stopwords[' '] = ' '\n",
    "    \n",
    "    segListSanitized = []\n",
    "\n",
    "    for word in seglist:\n",
    "        # translation\n",
    "        if word == 'omnigo':\n",
    "            word = '酷刻'\n",
    "        if word == 'Aibee':\n",
    "            word = '爱笔'\n",
    "        if word == 'ilife':\n",
    "            word = '爱乐福'\n",
    "        if word == 'oracleen':\n",
    "            word = '爱芽'\n",
    "        if word not in stopwords:\n",
    "            segListSanitized.append(word)\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # remove punctuations\n",
    "    text = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", text)\n",
    "    text = text.lower()\n",
    "    # seperate words\n",
    "    words = jieba.cut(text, cut_all=False)\n",
    "    seglist = list(words)\n",
    "    # remove stopwords\n",
    "    segListSanitized = removeStopWords(seglist)\n",
    "    print(f'Before sanitize, len: {len(seglist)}. After sanitize, len: {len(segListSanitized)}')\n",
    "\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(wordList, n):\n",
    "    '''\n",
    "    This function only generete N-Grams\n",
    "    '''\n",
    "    output = []\n",
    "    for i in range (len(wordList) - n + 1):\n",
    "        n_gram_temp = \"\".join(wordList[i:i+n])\n",
    "        output.append(n_gram_temp)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNgramsV2(wordList, n):\n",
    "    '''\n",
    "    This function genereates [1, N]-Grams\n",
    "    '''\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        temp_list = getNgrams(wordList, i+1)\n",
    "        temp = list(set(temp_list))\n",
    "        temp.sort(key=temp_list.index)\n",
    "        result.append(temp)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkEntity(output, company_df, position_df, school_df, degree_df):\n",
    "    company_entity = []\n",
    "    position_entity = []\n",
    "    school_entity = []\n",
    "    degree_entity = []\n",
    "    for index, li in enumerate(output):\n",
    "        print(f'process {index}-Gram')\n",
    "        \n",
    "        for term in li:\n",
    "            if len(term) <= 1:\n",
    "                continue\n",
    "            \n",
    "            # Link Company\n",
    "            for index, row in company_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name = name.lower()\n",
    "                if term == name:\n",
    "                    company_entity.append(term)\n",
    "                    print(f'company entity found: {term}')\n",
    "            \n",
    "            # Link Position\n",
    "            for index, row in position_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name = name.lower()\n",
    "                if term == name:\n",
    "                    position_entity.append(term)\n",
    "                    print(f'position entity found: {term}')\n",
    "            \n",
    "            # Link School\n",
    "            for index, row in school_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name = name.lower()\n",
    "                if term == name:\n",
    "                    school_entity.append(term)\n",
    "                    print(f'school entity found: {term}')\n",
    "            \n",
    "            # Link Degree\n",
    "            for index, row in degree_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name = name.lower()\n",
    "                if term == name:\n",
    "                    degree_entity.append(term)\n",
    "                    print(f'degree entity found: {term}')\n",
    "            \n",
    "    return company_entity, position_entity, school_entity, degree_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table_company_position(company_entity, position_entity):\n",
    "    company_list = []\n",
    "    position_list = []\n",
    "        \n",
    "    min_len = min(len(company_entity), len(position_entity))\n",
    "    \n",
    "    for i, s in enumerate(company_entity):\n",
    "        if i == min_len:\n",
    "            break\n",
    "        company_list.append(s)\n",
    "\n",
    "    for i, d in enumerate(position_entity):\n",
    "        if i == min_len:\n",
    "            break\n",
    "        position_list.append(d)\n",
    "\n",
    "    tb = pt.PrettyTable()\n",
    "    tb.add_column(\"Company\", company_list)\n",
    "    tb.add_column(\"Position\", position_list)\n",
    "    print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table_school_degree(school_entity, degree_entity):\n",
    "    school_list = []\n",
    "    degree_list = []\n",
    "\n",
    "    if len(degree_entity) == 0:\n",
    "        d = dict()\n",
    "        d= '本科'\n",
    "        degree_entity.append(d)\n",
    "        \n",
    "    min_len = min(len(school_entity), len(degree_entity))\n",
    "    \n",
    "    for i, s in enumerate(school_entity):\n",
    "        if i == min_len:\n",
    "            break\n",
    "        school_list.append(s)\n",
    "\n",
    "    for i, d in enumerate(degree_entity):\n",
    "        if i == min_len:\n",
    "            break\n",
    "        degree_list.append(d)\n",
    "\n",
    "    tb = pt.PrettyTable()\n",
    "    tb.add_column(\"School\", school_list)\n",
    "    tb.add_column(\"Degree\", degree_list)\n",
    "    print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(company_entity, position_entity, school_entity, degree_entity):\n",
    "    print_table_company_position(company_entity, position_entity)\n",
    "    print_table_school_degree(school_entity, degree_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dedup, company size: 11716\n",
      "after dedup, company size: 3571\n",
      "before dedup, position size: 5983\n",
      "after dedup, position size: 199\n"
     ]
    }
   ],
   "source": [
    "company_df = loadCompany()\n",
    "position_df = loadPosition()\n",
    "school_df = loadSchool()\n",
    "degree_df = loadDegree()\n",
    "member_df = loadMember()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = '__团队成员#1__先生是公司创始人,也是中国最有影响力的商界领袖之一。1982年,__团队成员#1__先生于华南理工大学毕业,进入TCL的前身-TTK家庭电器有限公司。1985年,他担任新成立的TCL通讯设备公司总经理,创立了TCL品牌。2003年,__团队成员#1__担任TCL集团股份有限公司董事长兼CEO,随后TCL集团整体上市。在他的领导下,2004年TCL一举收购了法国汤姆逊全球彩电业务与阿尔卡特全球手机业务。目前TCL集团已经成为拥有6万名员工,业务遍及全球80多个国家和地区。2013年,TCL集团营业总收入超过855亿元,液晶电视全球销量1766万台,实际产量全球第三,品牌销售全球第三;TCL手机全球销量5520万台,行业排名全球第五。2012年__团队成员#1__被新华网评为“最具社会责任感企业家”;2011年荣获《中国企业家》“最具影响力的25位企业领袖”终身成就奖;2009年被评为“CCTV中国经济年度人物十年商业领袖”;2008年获改革开放30年经济人物称号;2004年被评为Fortune杂志“亚洲年度经济人物”、TIME杂志和CNN全球最具影响力的25名商界人士,同年法国总统希拉克向__团队成员#1__先生颁发了法国国家荣誉勋章。__团队成员#1__是中共第十六大代表,第十届、第十一届、第十二届全国人大代表。__团队成员#1__担任的社会职务包括:中国电子视像行业协会会长;中国国际商会副会长;全国工商联执行委员、广东省工商联(总商会)副主席。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 325. After sanitize, len: 239\n",
      "process 0-Gram\n",
      "position entity found: 创始人\n",
      "school entity found: 华南理工大学\n",
      "school entity found: 华南理工大学\n",
      "position entity found: 总经理\n",
      "position entity found: 董事长\n",
      "position entity found: ceo\n",
      "process 1-Gram\n",
      "position entity found: 公司创始人\n",
      "process 2-Gram\n",
      "company entity found: tcl集团股份有限公司\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text1)\n",
    "output = generateNgramsV2(segListSanitized, 3)\n",
    "company_entity, position_entity, school_entity, degree_entity = linkEntity(output, company_df, position_df, school_df, degree_df)\n",
    "print_table(company_entity, position_entity, school_entity, degree_entity, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------+\n",
      "|       Company       | Position |\n",
      "+---------------------+----------+\n",
      "| tcl集团股份有限公司 |  创始人  |\n",
      "+---------------------+----------+\n",
      "+--------------+--------+\n",
      "|    School    | Degree |\n",
      "+--------------+--------+\n",
      "| 华南理工大学 |  本科  |\n",
      "+--------------+--------+\n"
     ]
    }
   ],
   "source": [
    "print_table(company_entity, position_entity, school_entity, degree_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
