{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo3\n",
    "In this notebook, I try to address output structure of this algorithm. The result should be a combination of degree and school, or position and company.\n",
    "E.g, `xxx本科是中山大学，在清华大学获得硕士学位`. Then I expect the result to be something like: `<中山大学, 本科>`,`<清华大学, 硕士>`\n",
    "\n",
    "Idea:\n",
    "+ Link entity seperately, do linking each n-gram, thus can make use of the order of text.\n",
    "+ Eliminate duplicate entities after linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import chardet\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSchool():\n",
    "    path1 = 'data/chinese_university_list.csv'\n",
    "    school_df = pd.read_csv(path1, header=None, delimiter=\",\", skiprows=4, names=[\"rank\", \"name\", \"code\", \"department\", \"city\", \"level\", \"notes\"])\n",
    "    school_df = pd.DataFrame(school_df, columns=['name'])\n",
    "    print(school_df.shape[0])\n",
    "    \n",
    "    path2 = 'data/all_university.csv'\n",
    "    school_global_df = pd.read_csv(path2, header=None, delimiter=',', skiprows=4, names=['Name_en', 'Name_ch', 'rank', 'score', 'location'])\n",
    "    school_global_df = pd.DataFrame(school_global_df, columns=['Name_ch'])\n",
    "    print(school_global_df.shape[0])\n",
    "    \n",
    "    school_df = pd.concat([school_df, school_global_df], axis=0, ignore_index=True)\n",
    "    print(school_df.shape[0])\n",
    "    return school_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDegree():\n",
    "    degree = {'name': ['学士', '硕士', '博士']}\n",
    "    degree_df = pd.DataFrame(degree)\n",
    "    print(degree_df)\n",
    "    return degree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMember():\n",
    "    path = 'data/member-data.csv'\n",
    "    member_df = pd.read_csv(path, header=None, delimiter=\",\", skiprows=1, names=['Company', 'No.', 'Resume', 'Position'])\n",
    "    member_df = pd.DataFrame(member_df, columns=['Resume'])\n",
    "    print(member_df.head())\n",
    "    return member_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(seglist):\n",
    "    stopwords = {}\n",
    "    fstop = open('data/stopwords_cn.txt', 'r', encoding='utf-8', errors='ignore')\n",
    "    for w in fstop:\n",
    "        stopwords[w.strip()] = w.strip()\n",
    "\n",
    "    fstop.close()\n",
    "    stopwords[' '] = ' '\n",
    "    \n",
    "    segListSanitized = []\n",
    "\n",
    "    for word in seglist:\n",
    "        if word not in stopwords:\n",
    "            segListSanitized.append(word)\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # remove punctuations\n",
    "    text = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", text)\n",
    "    text = text.lower()\n",
    "    # seperate words\n",
    "    words = jieba.cut(text, cut_all=False)\n",
    "    seglist = list(words)\n",
    "    # remove stopwords\n",
    "    segListSanitized = removeStopWords(seglist)\n",
    "    print(f'Before sanitize, len: {len(seglist)}. After sanitize, len: {len(segListSanitized)}')\n",
    "\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(wordList, n):\n",
    "    '''\n",
    "    This function only generete N-Grams\n",
    "    '''\n",
    "    output = []\n",
    "    for i in range (len(wordList) - n + 1):\n",
    "        n_gram_temp = \"\".join(wordList[i:i+n])\n",
    "        output.append(n_gram_temp)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNgrams(wordList, n):\n",
    "    '''\n",
    "    This function genereates [1, N]-Grams\n",
    "    '''\n",
    "    result = set()\n",
    "    for i in range(n):\n",
    "        temp = getNgrams(wordList, i+1)\n",
    "        result = result | temp\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNgramsV2(wordList, n):\n",
    "    '''\n",
    "    This function genereates [1, N]-Grams\n",
    "    '''\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        temp_list = getNgrams(wordList, i+1)\n",
    "        temp = list(set(temp_list))\n",
    "        temp.sort(key=temp_list.index)\n",
    "        result.append(temp)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('./test_50.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(a, b):\n",
    "    vector_a = np.mat(a)\n",
    "    vector_b = np.mat(b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEmbeddings(name):\n",
    "    words = jieba.cut(name, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    for word in word_list:\n",
    "        if word in model.vocab:\n",
    "            v += model[word]\n",
    "    \n",
    "    v /= len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entity_list(df, model):\n",
    "    '''\n",
    "    df: dafaframe\n",
    "    model: word embedding model\n",
    "    '''\n",
    "    \n",
    "    df['embeddings'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        # df.loc[index, 'embeddings'] = z\n",
    "        name = row['name']\n",
    "        if isinstance(name, float):\n",
    "            continue\n",
    "        name = name.lower()\n",
    "        if name in model.vocab:\n",
    "            vec = model[name]\n",
    "        else:\n",
    "            vec = generateEmbeddings(name)\n",
    "        df.set_value(index, 'embeddings', vec)\n",
    "\n",
    "    # print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkSchoolAndDegree(output, model, school_df, degree_df, school_threshold, degree_threshold):\n",
    "    for index, li in enumerate(output):\n",
    "        print(f'process {index}-Gram')\n",
    "        for term in li:\n",
    "            if len(term) <= 1:\n",
    "                continue\n",
    "            if term in model.vocab:\n",
    "                term_vec = model[term]\n",
    "                school_candidate = dict()\n",
    "\n",
    "                # Link School\n",
    "                for index, row in school_df.iterrows():\n",
    "                    name = row['name']\n",
    "                    if isinstance(name, float):\n",
    "                        continue\n",
    "                    name_vec = row['embeddings']\n",
    "                    sim = calculate_cosine_similarity(term_vec, name_vec)\n",
    "                    if (sim > school_threshold):\n",
    "                        school_candidate[name] = sim\n",
    "                if len(school_candidate) != 0:\n",
    "                    school_candidate = sorted(school_candidate.items(), key=lambda item:item[1], reverse=True)\n",
    "                    print(f'university entity found: {term}->{school_candidate[0][0]}, sim = {school_candidate[0][1]}')\n",
    "\n",
    "                # Link Degree\n",
    "                degree_candidate = dict()\n",
    "                for index, row in degree_df.iterrows():\n",
    "                    name = row['name']\n",
    "                    name_vec = row['embeddings']\n",
    "                    sim = calculate_cosine_similarity(term_vec, name_vec)\n",
    "                    if (sim > degree_threshold):\n",
    "                        degree_candidate[name] = sim\n",
    "                if len(degree_candidate) != 0:\n",
    "                    degree_candidate = sorted(degree_candidate.items(), key=lambda item:item[1], reverse=True)\n",
    "                    print(f'degree entity found: {term}->{degree_candidate[0][0]}, sim = {degree_candidate[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718\n",
      "949\n",
      "3667\n",
      "  name\n",
      "0   学士\n",
      "1   硕士\n",
      "2   博士\n",
      "                                              Resume\n",
      "0  __团队成员#1__先生是公司创始人,也是中国最有影响力的商界领袖之一。1982年,__团队...\n",
      "1  __团队成员#2__先生,现任TCL集团股份有限公司执行董事、总裁(COO)。1963年4月...\n",
      "2  __团队成员#3__女士:1972年7月出生,中山大学法学博士,高级经济师。1993年6月至...\n",
      "3  __团队成员#4__先生,1965年7月出生,东方电气集团党组副书记、副总经理,兼任东方电气...\n",
      "4  __团队成员#5__女士,现任TCL多媒体集团有限公司非执行独立董事、A8新媒体集团非执行独...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "school_df = loadSchool()\n",
    "degree_df = loadDegree()\n",
    "member_df = loadMember()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "school_df = preprocess_entity_list(school_df, model)\n",
    "degree_df = preprocess_entity_list(degree_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '__团队成员#1__先生是公司创始人,也是中国最有影响力的商界领袖之一。1982年,__团队成员#1__先生于华南理工大学毕业,进入TCL的前身-TTK家庭电器有限公司。1985年,他担任新成立的TCL通讯设备公司总经理,创立了TCL品牌。2003年,__团队成员#1__担任TCL集团股份有限公司董事长兼CEO,随后TCL集团整体上市。在他的领导下,2004年TCL一举收购了法国汤姆逊全球彩电业务与阿尔卡特全球手机业务。目前TCL集团已经成为拥有6万名员工,业务遍及全球80多个国家和地区。2013年,TCL集团营业总收入超过855亿元,液晶电视全球销量1766万台,实际产量全球第三,品牌销售全球第三;TCL手机全球销量5520万台,行业排名全球第五。2012年__团队成员#1__被新华网评为“最具社会责任感企业家”;2011年荣获《中国企业家》“最具影响力的25位企业领袖”终身成就奖;2009年被评为“CCTV中国经济年度人物十年商业领袖”;2008年获改革开放30年经济人物称号;2004年被评为Fortune杂志“亚洲年度经济人物”、TIME杂志和CNN全球最具影响力的25名商界人士,同年法国总统希拉克向__团队成员#1__先生颁发了法国国家荣誉勋章。__团队成员#1__是中共第十六大代表,第十届、第十一届、第十二届全国人大代表。__团队成员#1__担任的社会职务包括:中国电子视像行业协会会长;中国国际商会副会长;全国工商联执行委员、广东省工商联(总商会)副主席。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 325. After sanitize, len: 239\n",
      "process 0-Gram\n",
      "university entity found: 华南理工大学->华南理工大学, sim = 1.000000029802326\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text)\n",
    "output = generateNgramsV2(segListSanitized, 3)\n",
    "linkSchoolAndDegree(output, model, school_df, degree_df, 0.9, 0.98)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = '__团队成员#2__先生,现任TCL集团股份有限公司执行董事、总裁(COO)。1963年4月出生,博士,毕业于西安交通大学。薄先生1988年至1993年间任陕西财经学院贸易经济系副主任,1993年5月至2000年5月间任深圳航空公司总会计师,是深圳航空公司创始人之一。薄先生2000年5月至2004年4月间任TCL信息产业集团副总裁、财务总监,2004年4月至2005年1月间任TCL集团部品事业本部副总裁,2005年1月至2005年10月间任TCL集团股份有限公司人力资源部部长、总裁办主任,2005年10月至2006年11月间任TCL集团股份有限公司控股子公司TTE Corporation执行副总裁,2006年6月至2007年9月间任TCL集团股份有限公司人力资源总监,2006年8月至2007年10月间任TCL集团股份有限公司副总裁,2007年10月至2008年6月间任高级副总裁,2008年6月至2011年6月,任TCL集团股份有限公司首席运营官,2011年6月至今任TCL集团股份有限公司总裁(COO),2012年12月24日起任深圳市华星光电技术有限公司CEO。__团队成员#2__先生现兼任TCL多媒体科技控股有限公司执行董事、深圳市华星光电技术有限公司董事、翰林汇信息产业股份有限公司董事长、TCL教育网有限公司董事长、电大在线远程教育技术有限公司副董事长。__团队成员#2__先生于二零一四年十月二十三日调任为TCL多媒体科技控股有限公司之执行董事，并获委任为策略执行委员会主席。__团队成员#2__先生获委任为TCL多媒体科技控股有限公司首席执行官,自二零一五年六月二十五日起生效。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 330. After sanitize, len: 264\n",
      "process 0-Gram\n",
      "degree entity found: 博士->博士, sim = 1.0\n",
      "university entity found: 西安交通大学->西安交通大学, sim = 1.0000000596046448\n",
      "university entity found: 财经学院->宁波财经学院, sim = 0.9081512997142207\n",
      "process 1-Gram\n",
      "degree entity found: 博士毕业->硕士, sim = 0.9167363941669464\n",
      "process 2-Gram\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text2)\n",
    "output = generateNgramsV2(segListSanitized, 3)\n",
    "linkSchoolAndDegree(output, model, school_df, degree_df, 0.9, 0.90)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = '__团队成员#6__先生,1980年7月生,硕士研究生学历。2002年,福州大学经济学本科毕业;2006年,云南大学法律硕士研究生毕业。2006年8月至2014年2月,任职国泰君安证券股份有限公司,历任国泰君安证券香港公司财务顾问部高级经理、总经理,深圳总部机构客户部总监,从事香港与中国资本市场的投资银行业务。2014年3月加入TCL集团股份有限公司,任公司董事会办公室主任;2014年4月起任公司董事会秘书;2014年12月起任公司执委会成员;2015年4月起任TCL集团控股子公司全球播有限公司董事;2015年5月起任TCL通讯科技控股有限公司(02618.HK)非执行董事。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 139. After sanitize, len: 111\n",
      "process 0-Gram\n",
      "degree entity found: 硕士->硕士, sim = 1.0\n",
      "degree entity found: 研究生->硕士, sim = 0.9259832799434662\n",
      "university entity found: 福州大学->福州大学, sim = 1.0000000596046448\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 云南大学->云南大学, sim = 1.0000000596046448\n",
      "process 1-Gram\n",
      "degree entity found: 硕士研究生->硕士, sim = 0.9260654151439667\n",
      "degree entity found: 研究生毕业->硕士, sim = 0.9024443626403809\n",
      "process 2-Gram\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text3)\n",
    "output = generateNgramsV2(segListSanitized, 3)\n",
    "linkSchoolAndDegree(output, model, school_df, degree_df, 0.9, 0.90)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['团队', '成员', '6', '先生', '1980', '年', '7', '月生', '硕士', '研究生', '学历', '2002', '年', '福州大学', '经济学', '本科毕业', '2006', '年', '云南大学', '法律硕士', '研究生', '毕业', '2006', '年', '8', '月', '2014', '年', '2', '月', '任职', '国泰君安证券股份有限公司', '历任', '国泰君安', '证券', '香港', '公司', '财务顾问', '部', '高级', '经理', '总经理', '深圳', '总部', '机构', '客户部', '总监', '从事', '香港', '中国', '资本', '市场', '投资', '银行业务', '2014', '年', '3', '月', '加入', 'tcl', '集团股份', '有限公司', '任', '公司', '董事会', '办公室', '主任', '2014', '年', '4', '月', '起任', '公司', '董事会', '秘书', '2014', '年', '12', '月', '起任', '公司', '执委会', '成员', '2015', '年', '4', '月', '起任', 'tcl', '集团', '控股', '子公司', '全球', '播', '有限公司', '董事', '2015', '年', '5', '月', '起任', 'tcl', '通讯', '科技', '控股', '有限公司', '02618', 'hk', '非', '执行', '董事']\n"
     ]
    }
   ],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handle No.0 text\n",
      "Before sanitize, len: 325. After sanitize, len: 239\n",
      "process 0-Gram\n",
      "university entity found: 华南理工大学->华南理工大学, sim = 1.000000029802326\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:03:43.105396 sec\n",
      "\n",
      "Handle No.1 text\n",
      "Before sanitize, len: 330. After sanitize, len: 264\n",
      "process 0-Gram\n",
      "degree entity found: 博士->博士, sim = 1.0\n",
      "university entity found: 西安交通大学->西安交通大学, sim = 1.0000000596046448\n",
      "university entity found: 财经学院->宁波财经学院, sim = 0.9081512997142207\n",
      "process 1-Gram\n",
      "degree entity found: 博士毕业->硕士, sim = 0.9167363941669464\n",
      "process 2-Gram\n",
      "cost time: 0:02:46.263789 sec\n",
      "\n",
      "Handle No.2 text\n",
      "Before sanitize, len: 134. After sanitize, len: 108\n",
      "process 0-Gram\n",
      "university entity found: 中山大学->中山大学, sim = 1.0\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:09.030211 sec\n",
      "\n",
      "Handle No.3 text\n",
      "Before sanitize, len: 187. After sanitize, len: 149\n",
      "process 0-Gram\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 上海交通大学->上海交通大学, sim = 1.0\n",
      "degree entity found: 研究生->硕士, sim = 0.9259832799434662\n",
      "university entity found: 重庆大学->重庆大学, sim = 1.0000000596046448\n",
      "degree entity found: 博士->博士, sim = 1.0\n",
      "university entity found: 西南财经大学->西南财经大学, sim = 1.0000000596046448\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:02:17.913340 sec\n",
      "\n",
      "Handle No.4 text\n",
      "Before sanitize, len: 126. After sanitize, len: 94\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:32.992318 sec\n",
      "\n",
      "Handle No.5 text\n",
      "Before sanitize, len: 139. After sanitize, len: 111\n",
      "process 0-Gram\n",
      "degree entity found: 硕士->硕士, sim = 1.0\n",
      "degree entity found: 研究生->硕士, sim = 0.9259832799434662\n",
      "university entity found: 福州大学->福州大学, sim = 1.0000000596046448\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 云南大学->云南大学, sim = 1.0000000596046448\n",
      "process 1-Gram\n",
      "degree entity found: 硕士研究生->硕士, sim = 0.9260654151439667\n",
      "process 2-Gram\n",
      "cost time: 0:02:28.709828 sec\n",
      "\n",
      "Handle No.6 text\n",
      "Before sanitize, len: 140. After sanitize, len: 116\n",
      "process 0-Gram\n",
      "university entity found: 外交学院->外交学院, sim = 1.000000029802326\n",
      "degree entity found: 研究生->硕士, sim = 0.9259832799434662\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:02:05.812039 sec\n",
      "\n",
      "Handle No.7 text\n",
      "Before sanitize, len: 574. After sanitize, len: 411\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:04:37.591816 sec\n",
      "\n",
      "Handle No.8 text\n",
      "Before sanitize, len: 150. After sanitize, len: 119\n",
      "process 0-Gram\n",
      "university entity found: 西北师范大学->西北师范大学, sim = 1.0000000596046448\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 商学院->郑州商学院, sim = 0.9071498487162017\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:24.122305 sec\n",
      "\n",
      "Handle No.9 text\n",
      "Before sanitize, len: 115. After sanitize, len: 88\n",
      "process 0-Gram\n",
      "university entity found: 清华大学->清华大学, sim = 1.0\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:36.559164 sec\n",
      "\n",
      "Handle No.10 text\n",
      "Before sanitize, len: 117. After sanitize, len: 84\n",
      "process 0-Gram\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "process 1-Gram\n",
      "university entity found: 电子科技大学->电子科技大学, sim = 1.0\n",
      "process 2-Gram\n",
      "cost time: 0:00:36.513410 sec\n",
      "\n",
      "Handle No.11 text\n",
      "Before sanitize, len: 262. After sanitize, len: 211\n",
      "process 0-Gram\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 商学院->郑州商学院, sim = 0.9071498487162017\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:02:19.886727 sec\n",
      "\n",
      "Handle No.12 text\n",
      "Before sanitize, len: 188. After sanitize, len: 124\n",
      "process 0-Gram\n",
      "degree entity found: 硕士->硕士, sim = 1.0\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "degree entity found: 研究生->硕士, sim = 0.9259832799434662\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:50.273964 sec\n",
      "\n",
      "Handle No.13 text\n",
      "Before sanitize, len: 467. After sanitize, len: 372\n",
      "process 0-Gram\n",
      "degree entity found: 本科->硕士, sim = 0.9303888976573944\n",
      "university entity found: 华南理工大学->华南理工大学, sim = 1.000000029802326\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 武汉->武汉光谷职业学院, sim = 0.9132345485049689\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:35.631745 sec\n",
      "\n",
      "Handle No.14 text\n",
      "Before sanitize, len: 181. After sanitize, len: 141\n",
      "process 0-Gram\n",
      "university entity found: 北京大学->北京大学, sim = 1.0\n",
      "university entity found: 汕头大学->汕头大学, sim = 1.0\n",
      "degree entity found: 教授->博士, sim = 0.9146097251540259\n",
      "university entity found: 中山大学->中山大学, sim = 1.0\n",
      "university entity found: 南京师范大学->南京师范大学, sim = 1.000000029802326\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:48.809888 sec\n",
      "\n",
      "Handle No.15 text\n",
      "Before sanitize, len: 127. After sanitize, len: 85\n",
      "process 0-Gram\n",
      "university entity found: 商学院->郑州商学院, sim = 0.9071498487162017\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:52.001307 sec\n",
      "\n",
      "Handle No.16 text\n",
      "Before sanitize, len: 26. After sanitize, len: 20\n",
      "process 0-Gram\n",
      "university entity found: 财经学院->宁波财经学院, sim = 0.9081512997142207\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:33.514678 sec\n",
      "\n",
      "Handle No.17 text\n",
      "Before sanitize, len: 135. After sanitize, len: 99\n",
      "process 0-Gram\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "university entity found: 首都经济贸易大学->首都经济贸易大学, sim = 1.000000029802326\n",
      "cost time: 0:01:27.836151 sec\n",
      "\n",
      "Handle No.18 text\n",
      "Before sanitize, len: 16. After sanitize, len: 8\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:03.567794 sec\n",
      "\n",
      "Handle No.19 text\n",
      "Before sanitize, len: 12. After sanitize, len: 7\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:04.385044 sec\n",
      "\n",
      "Handle No.20 text\n",
      "Before sanitize, len: 81. After sanitize, len: 62\n",
      "process 0-Gram\n",
      "university entity found: 重庆大学->重庆大学, sim = 1.0000000596046448\n",
      "degree entity found: 博士->博士, sim = 1.0\n",
      "degree entity found: 教授->博士, sim = 0.9146097251540259\n",
      "degree entity found: 研究生->硕士, sim = 0.9259832799434662\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:28.781097 sec\n",
      "\n",
      "Handle No.21 text\n",
      "Before sanitize, len: 116. After sanitize, len: 90\n",
      "process 0-Gram\n",
      "university entity found: 理工学院->潍坊理工学院, sim = 0.9093460041882638\n",
      "degree entity found: 硕士->硕士, sim = 1.0\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:34.803065 sec\n",
      "\n",
      "Handle No.22 text\n",
      "Before sanitize, len: 90. After sanitize, len: 66\n",
      "process 0-Gram\n",
      "degree entity found: 本科->硕士, sim = 0.9303888976573944\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:23.218352 sec\n",
      "\n",
      "Handle No.23 text\n",
      "Before sanitize, len: 310. After sanitize, len: 242\n",
      "process 0-Gram\n",
      "university entity found: 中国科学院->中国科学院大学, sim = 0.9003123641014099\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:02:36.642507 sec\n",
      "\n",
      "Handle No.24 text\n",
      "Before sanitize, len: 90. After sanitize, len: 60\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:35.100241 sec\n",
      "\n",
      "Handle No.25 text\n",
      "Before sanitize, len: 133. After sanitize, len: 109\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:31.486602 sec\n",
      "\n",
      "Handle No.26 text\n",
      "Before sanitize, len: 220. After sanitize, len: 181\n",
      "process 0-Gram\n",
      "degree entity found: 硕士->硕士, sim = 1.0\n",
      "degree entity found: 研究生->硕士, sim = 0.9259832799434662\n",
      "degree entity found: 教授->博士, sim = 0.9146097251540259\n",
      "university entity found: 湖南->湖南工商大学, sim = 0.9128547738195922\n",
      "university entity found: 商学院->郑州商学院, sim = 0.9071498487162017\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "process 1-Gram\n",
      "degree entity found: 硕士研究生->硕士, sim = 0.9260654151439667\n",
      "university entity found: 惠州学院->惠州学院, sim = 1.0\n",
      "university entity found: 衡阳师范学院->衡阳师范学院, sim = 1.0000000596046448\n",
      "university entity found: 湖南农业大学->湖南农业大学, sim = 1.000000029802326\n",
      "process 2-Gram\n",
      "cost time: 0:02:02.446588 sec\n",
      "\n",
      "Handle No.27 text\n",
      "Before sanitize, len: 152. After sanitize, len: 116\n",
      "process 0-Gram\n",
      "university entity found: 师范大学->南宁师范大学, sim = 0.9128770340491656\n",
      "degree entity found: 博士->博士, sim = 1.0\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "degree entity found: 教授->博士, sim = 0.9146097251540259\n",
      "process 1-Gram\n",
      "university entity found: 华南师范大学->华南师范大学, sim = 1.0000000596046448\n",
      "process 2-Gram\n",
      "cost time: 0:01:58.821987 sec\n",
      "\n",
      "Handle No.28 text\n",
      "Before sanitize, len: 208. After sanitize, len: 166\n",
      "process 0-Gram\n",
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 广西大学->广西大学, sim = 1.0\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:03:13.600404 sec\n",
      "\n",
      "Handle No.29 text\n",
      "Before sanitize, len: 172. After sanitize, len: 126\n",
      "process 0-Gram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree entity found: 本科毕业->硕士, sim = 0.9262227118015289\n",
      "university entity found: 山东大学->山东大学, sim = 1.0000000596046448\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:48.303338 sec\n",
      "\n",
      "Handle No.30 text\n",
      "Before sanitize, len: 119. After sanitize, len: 89\n",
      "process 0-Gram\n",
      "degree entity found: 硕士->硕士, sim = 1.0\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "process 1-Gram\n",
      "degree entity found: 硕士学历->硕士, sim = 0.9123177826404572\n",
      "process 2-Gram\n",
      "cost time: 0:00:58.979360 sec\n",
      "\n",
      "Handle No.31 text\n",
      "Before sanitize, len: 99. After sanitize, len: 74\n",
      "process 0-Gram\n",
      "university entity found: 暨南大学->暨南大学, sim = 1.0\n",
      "degree entity found: 教授->博士, sim = 0.9146097251540259\n",
      "university entity found: 中国人民大学->中国人民大学, sim = 1.0\n",
      "university entity found: 商学院->郑州商学院, sim = 0.9071498487162017\n",
      "degree entity found: 博士->博士, sim = 1.0\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:01:11.983107 sec\n",
      "\n",
      "Handle No.32 text\n",
      "Before sanitize, len: 12. After sanitize, len: 7\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:07.387656 sec\n",
      "\n",
      "Handle No.33 text\n",
      "Before sanitize, len: 178. After sanitize, len: 132\n",
      "process 0-Gram\n",
      "degree entity found: 硕士->硕士, sim = 1.0\n",
      "university entity found: 清华大学->清华大学, sim = 1.0\n",
      "university entity found: 天津大学->天津大学, sim = 1.000000029802326\n",
      "degree entity found: 教授->博士, sim = 0.9146097251540259\n",
      "university entity found: 清华->清华大学, sim = 0.9318847615650154\n",
      "process 1-Gram\n",
      "degree entity found: 硕士毕业->硕士, sim = 0.9301680624485016\n",
      "process 2-Gram\n",
      "cost time: 0:02:02.093219 sec\n",
      "\n",
      "Handle No.34 text\n",
      "Before sanitize, len: 11. After sanitize, len: 5\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:11.145763 sec\n",
      "\n",
      "Handle No.35 text\n",
      "Before sanitize, len: 230. After sanitize, len: 172\n",
      "process 0-Gram\n",
      "university entity found: 商学院->郑州商学院, sim = 0.9071498487162017\n",
      "university entity found: 大学->吉林外国语大学, sim = 0.9060334598685178\n",
      "degree entity found: 博士->博士, sim = 1.0\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:02:50.172310 sec\n",
      "\n",
      "Handle No.36 text\n",
      "Before sanitize, len: 14. After sanitize, len: 8\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:09.513997 sec\n",
      "\n",
      "Handle No.37 text\n",
      "Before sanitize, len: 10. After sanitize, len: 5\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:07.243985 sec\n",
      "\n",
      "Handle No.38 text\n",
      "Before sanitize, len: 10. After sanitize, len: 5\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:07.265953 sec\n",
      "\n",
      "Handle No.39 text\n",
      "Before sanitize, len: 11. After sanitize, len: 7\n",
      "process 0-Gram\n",
      "process 1-Gram\n",
      "process 2-Gram\n",
      "cost time: 0:00:12.157998 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in member_df.iterrows():\n",
    "    if index == 40:\n",
    "        break\n",
    "    print(f'Handle No.{index} text')\n",
    "    start = datetime.datetime.now()\n",
    "    text = row['Resume']\n",
    "    segListSanitized = preprocess(text)\n",
    "    output = generateNgramsV2(segListSanitized, 3)\n",
    "    linkSchoolAndDegree(output, model, school_df, degree_df, 0.9, 0.91)\n",
    "    end = datetime.datetime.now()\n",
    "    print(f'cost time: {end - start} sec')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
