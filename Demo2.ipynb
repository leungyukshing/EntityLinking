{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo1\n",
    "version2, based on version1\n",
    "This is a demo. What I want to achieve in this demo?\n",
    "+ improve company link accuracy\n",
    "\n",
    "Actually there are 2 problems concerning the accuracy\n",
    "+ Some company's name cannot be found in dictionary, those the key information is lost. 广州xxx公司\n",
    "+ Some irrelerant terms are linked to a company name, like the location. 深圳->深圳xxx公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import chardet\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCompany():\n",
    "    path1 = 'data/company_list_ch.csv'\n",
    "    company_ch_df = pd.read_csv(path1, header=None, delimiter=\",\", skiprows=2, names=['rank', 'name', 'Location', 'Income'])\n",
    "    company_ch_df = pd.DataFrame(company_ch_df, columns=['name'])\n",
    "    path2 = 'data/member-data.csv'\n",
    "    company_df = pd.read_csv(path2, header=None, delimiter=\",\", skiprows=2, names=['name', 'No.', 'Resume', 'Position'])\n",
    "    company_df = pd.DataFrame(company_df, columns=['name'])\n",
    "    company_ch_df = pd.concat([company_ch_df, company_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    print(f'before dedup, size: {company_ch_df.shape[0]}')\n",
    "    company_ch_df = company_ch_df.drop_duplicates(subset=['name'], keep='first')\n",
    "    print(f'after dedup, size: {company_ch_df.shape[0]}')\n",
    "    print(type(company_ch_df))\n",
    "    print(company_ch_df.tail())\n",
    "    return company_ch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMember():\n",
    "    path = 'data/member-data.csv'\n",
    "    member_df = pd.read_csv(path, header=None, delimiter=\",\", skiprows=1, names=['Company', 'No.', 'Resume', 'Position'])\n",
    "    member_df = pd.DataFrame(member_df, columns=['Resume'])\n",
    "    print(member_df.head())\n",
    "    return member_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text\n",
    "+ remove punctuations\n",
    "+ remove stopwords\n",
    "+ to lower letter for regconition later\n",
    "+ generate N-grams to link entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(seglist):\n",
    "    stopwords = {}\n",
    "    fstop = open('data/stopwords_cn.txt', 'r', encoding='utf-8', errors='ignore')\n",
    "    for w in fstop:\n",
    "        stopwords[w.strip()] = w.strip()\n",
    "\n",
    "    fstop.close()\n",
    "    stopwords[' '] = ' '\n",
    "    \n",
    "    segListSanitized = []\n",
    "\n",
    "    for word in seglist:\n",
    "        if word == 'omnigo':\n",
    "            word = '酷刻'\n",
    "        if word == 'Aibee':\n",
    "            word = '爱笔'\n",
    "        if word == 'ilife':\n",
    "            word = '爱乐福'\n",
    "        if word == 'oracleen':\n",
    "            word = '爱芽'\n",
    "        if word not in stopwords:\n",
    "            segListSanitized.append(word)\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # remove punctuations\n",
    "    text = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", text)\n",
    "    text = text.lower()\n",
    "    # seperate words\n",
    "    words = jieba.cut(text, cut_all=False)\n",
    "    seglist = list(words)\n",
    "    # remove stopwords\n",
    "    segListSanitized = removeStopWords(seglist)\n",
    "    print(f'Before sanitize, len: {len(seglist)}. After sanitize, len: {len(segListSanitized)}')\n",
    "\n",
    "    return segListSanitized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(wordList, n):\n",
    "    '''\n",
    "    This function only generete N-Grams\n",
    "    '''\n",
    "    output = set()\n",
    "    for i in range (len(wordList) - n + 1):\n",
    "        n_gram_temp = \"\".join(wordList[i:i+n])\n",
    "        output.add(n_gram_temp)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNgrams(wordList, n):\n",
    "    '''\n",
    "    This function genereates [1, N]-Grams\n",
    "    '''\n",
    "    result = set()\n",
    "    for i in range(n):\n",
    "        temp = getNgrams(wordList, i+1)\n",
    "        result = result | temp\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('./test_50.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(a, b):\n",
    "    vector_a = np.mat(a)\n",
    "    vector_b = np.mat(b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEmbeddings(name):\n",
    "    words = jieba.cut(name, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    for word in word_list:\n",
    "        if word in model.vocab:\n",
    "            v += model[word]\n",
    "    \n",
    "    v /= len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IDF(df):\n",
    "    company_num = 0\n",
    "    m = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        name = row['name']\n",
    "        name = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", name)\n",
    "        name = name.lower()\n",
    "        if isinstance(name, float) or name == \" \":\n",
    "            continue\n",
    "        company_num += 1\n",
    "        words = jieba.cut(name, cut_all=False)\n",
    "        word_list = list(words)\n",
    "        for word in word_list:\n",
    "            if word in m.keys():\n",
    "                m[word] +=1\n",
    "            else:\n",
    "                m[word] = 1\n",
    "    \n",
    "    idf = dict()\n",
    "    \n",
    "    for (k, v) in m.items():\n",
    "        idf[k] = math.log(((1+company_num) / v), 10)\n",
    "    \n",
    "    # Normalize min-max\n",
    "    v = idf.values()\n",
    "    max_value = max(v)\n",
    "    min_value = min(v)\n",
    "    denom = max_value - min_value\n",
    "    for (k, v) in idf.items():\n",
    "        idf[k] = (idf[k] - min_value) / denom\n",
    "\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEmbeddingsWithIDF(name, idf):\n",
    "    words = jieba.cut(name, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    for word in word_list:\n",
    "        if word in model.vocab:\n",
    "            v += model[word] * idf[word]\n",
    "    \n",
    "    v /= len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entity_list(df, model):\n",
    "    '''\n",
    "    df: dafaframe\n",
    "    model: word embedding model\n",
    "    '''\n",
    "    \n",
    "    df['embeddings'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        # df.loc[index, 'embeddings'] = z\n",
    "        name = row['name']\n",
    "        if isinstance(name, float):\n",
    "            continue\n",
    "        name = name.lower()\n",
    "        if name in model.vocab:\n",
    "            vec = model[name]\n",
    "        else:\n",
    "            vec = generateEmbeddings(name)\n",
    "        df.set_value(index, 'embeddings', vec)\n",
    "\n",
    "    # print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entity_list_withIDF(df, model, idf):\n",
    "    '''\n",
    "    df: dafaframe\n",
    "    model: word embedding model\n",
    "    idf: IDF for each word\n",
    "    '''\n",
    "    \n",
    "    df['embeddings_idf'] = ''\n",
    "    for index, row in df.iterrows():\n",
    "        name = row['name']\n",
    "        name = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", name)\n",
    "        name = name.lower()\n",
    "        if isinstance(name, float):\n",
    "            continue\n",
    "        if name in model.vocab:\n",
    "            vec = model[name]\n",
    "        else:\n",
    "            vec = generateEmbeddingsWithIDF(name, idf)\n",
    "        df.set_value(index, 'embeddings_idf', vec)\n",
    "\n",
    "    # print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkCompany(output, model, company_df, company_threshold1, company_threshold2):\n",
    "    for term in output:\n",
    "        if len(term) <= 1:\n",
    "            continue\n",
    "        if term in model.vocab:\n",
    "            term_vec = model[term]\n",
    "            \n",
    "            # Link Company\n",
    "            company_candidate = dict()\n",
    "            for index, row in company_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name_vec_idf = row['embeddings_idf']\n",
    "                sim = calculate_cosine_similarity(term_vec, name_vec_idf)\n",
    "                if (sim > company_threshold1):\n",
    "                    company_candidate[name] = sim\n",
    "            if len(company_candidate) != 0:\n",
    "                company_candidate = sorted(company_candidate.items(), key=lambda item:item[1], reverse=True)\n",
    "                print(f'company entity found: {term}->{company_candidate[0][0]}, sim = {company_candidate[0][1]}')\n",
    "        else:\n",
    "            term_vec = generateEmbeddings(term)\n",
    "            for index, row  in company_df.iterrows():\n",
    "                name = row['name']\n",
    "                if isinstance(name, float):\n",
    "                    continue\n",
    "                name_vec = row['embeddings']\n",
    "                sim = calculate_cosine_similarity(term_vec, name_vec)\n",
    "                #if term == \"爱乐福\" and name == \"爱乐福（深圳）科技有限公司\":\n",
    "                #    print(f'term: {term}, sim: {sim}')\n",
    "                if (sim == 0.0 or sim > company_threshold2):\n",
    "                    is_match = exact_match(name, term)\n",
    "                    if is_match:\n",
    "                        print(f'company entity found by exact match: {term}->{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(entity, term):\n",
    "    # print(f'exact_match, entity: {entity}, term: {term}')\n",
    "    keyword = extractKeyword(term)\n",
    "    is_match = False\n",
    "    for key in keyword:\n",
    "        idx = entity.find(key)\n",
    "        if idx != -1:\n",
    "            is_match = True\n",
    "            print(f'match {key}')\n",
    "    return is_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractKeyword(term):\n",
    "    '''\n",
    "    Extract keyword in a term, whose embedding can not be found in vocabulary\n",
    "    Return a list\n",
    "    '''\n",
    "    words = jieba.cut(term, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    word_list = getNgrams(word_list, 2)\n",
    "    v = np.zeros((200))\n",
    "    keyword = []\n",
    "    for word in word_list:\n",
    "        if word not in model.vocab:\n",
    "            # print(f'keyword found: {word}')\n",
    "            keyword.append(word)\n",
    "    return keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Resume\n",
      "0  __团队成员#1__先生是公司创始人,也是中国最有影响力的商界领袖之一。1982年,__团队...\n",
      "1  __团队成员#2__先生,现任TCL集团股份有限公司执行董事、总裁(COO)。1963年4月...\n",
      "2  __团队成员#3__女士:1972年7月出生,中山大学法学博士,高级经济师。1993年6月至...\n",
      "3  __团队成员#4__先生,1965年7月出生,东方电气集团党组副书记、副总经理,兼任东方电气...\n",
      "4  __团队成员#5__女士,现任TCL多媒体集团有限公司非执行独立董事、A8新媒体集团非执行独...\n",
      "before dedup, size: 11716\n",
      "after dedup, size: 3571\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                 name\n",
      "11669  淄博大亚金属科技股份有限公司\n",
      "11681        紫光股份有限公司\n",
      "11712      紫光西部数据有限公司\n",
      "11713   紫罗兰家纺科技股份有限公司\n",
      "11714    卒子科技（深圳）有限公司\n"
     ]
    }
   ],
   "source": [
    "member_df = loadMember()\n",
    "company_df = loadCompany()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name                                         embeddings  \\\n",
      "0   中国石油化工集团有限公司\\n  [3.555182367563248e-05, -0.0002575131878256797...   \n",
      "1  中国石油天然气集团有限公司\\n  [0.00024397050961852073, -0.000617146184667945...   \n",
      "2       国家电网有限公司\\n  [0.00022917279973626138, -0.000968194492161274...   \n",
      "3     中国建筑股份有限公司\\n  [0.00037391087505966425, -0.001663828268647194...   \n",
      "4   中国工商银行股份有限公司\\n  [4.123697523027658e-05, -0.0013217980042099953...   \n",
      "\n",
      "                                      embeddings_idf  \n",
      "0  [0.00021867530420422555, 0.0003110994771122932...  \n",
      "1  [0.0004270939901471138, -4.853351972997189e-05...  \n",
      "2  [0.00041229628026485444, -0.000399581827223300...  \n",
      "3  [0.0003339895379031077, -0.0004802231770008802...  \n",
      "4  [0.00019588854687754064, -0.000362079134210944...  \n"
     ]
    }
   ],
   "source": [
    "company_idf = calculate_IDF(company_df)\n",
    "company_df = preprocess_entity_list(company_df, model)\n",
    "company_df = preprocess_entity_list_withIDF(company_df, model, company_idf)\n",
    "print(company_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '__团队成员#1__先生是公司创始人,也是中国最有影响力的商界领袖之一。1982年,__团队成员#1__先生于华南理工大学毕业,进入TCL的前身-TTK家庭电器有限公司。1985年,他担任新成立的TCL通讯设备公司总经理,创立了TCL品牌。2003年,__团队成员#1__担任TCL集团股份有限公司董事长兼CEO,随后TCL集团整体上市。在他的领导下,2004年TCL一举收购了法国汤姆逊全球彩电业务与阿尔卡特全球手机业务。目前TCL集团已经成为拥有6万名员工,业务遍及全球80多个国家和地区。2013年,TCL集团营业总收入超过855亿元,液晶电视全球销量1766万台,实际产量全球第三,品牌销售全球第三;TCL手机全球销量5520万台,行业排名全球第五。2012年__团队成员#1__被新华网评为“最具社会责任感企业家”;2011年荣获《中国企业家》“最具影响力的25位企业领袖”终身成就奖;2009年被评为“CCTV中国经济年度人物十年商业领袖”;2008年获改革开放30年经济人物称号;2004年被评为Fortune杂志“亚洲年度经济人物”、TIME杂志和CNN全球最具影响力的25名商界人士,同年法国总统希拉克向__团队成员#1__先生颁发了法国国家荣誉勋章。__团队成员#1__是中共第十六大代表,第十届、第十一届、第十二届全国人大代表。__团队成员#1__担任的社会职务包括:中国电子视像行业协会会长;中国国际商会副会长;全国工商联执行委员、广东省工商联(总商会)副主席。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 325. After sanitize, len: 239\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text)\n",
    "output = generateNgrams(segListSanitized, 3)\n",
    "linkCompany(output, model, company_df, 0.98, 0.9)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = '__团队成员#1__，Omnigo机器人CEO。毕业于华中科技大学，原uArm创始团队核心成员，uArm机械臂主创设计师。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 27. After sanitize, len: 18\n",
      "match 酷刻\n",
      "company entity found by exact match: 酷刻->广州酷刻科技有限公司\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text2)\n",
    "output = generateNgrams(segListSanitized, 3)\n",
    "linkCompany(output, model, company_df, 0.98, 0.9)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                                 广州酷刻科技有限公司\n",
       "embeddings    [0.00019766974612139165, -0.001492998823523521...\n",
       "Name: 3230, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df.loc[3230,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = '__团队成员#1__，北京爱国者新能源科技发展有限公司 CEO。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 16. After sanitize, len: 10\n",
      "company entity found: 北京->宝希（北京）科技有限公司, sim = 0.9760900424845506\n",
      "company entity found: 发展->深圳市迈迪加科技发展有限公司, sim = 0.9604227663245726\n",
      "sim: 0.9713396702727501\n",
      "company entity found: 爱国者->爱国者电子科技有限公司, sim = 0.9713396702727501\n",
      "company entity found: 科技->多玛凯拔科技有限公司, sim = 1.0000000094492707\n",
      "company entity found: 新能源->上海烯美新能源科技有限公司, sim = 0.9637615946079356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text3)\n",
    "output = generateNgrams(segListSanitized, 3)\n",
    "linkCompany(output, model, company_df, 0.95, 0.9)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = '__团队成员#1__,为爱漫科技（北京）有限公司执行董事'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 15. After sanitize, len: 9\n",
      "company entity found: 北京->宝希（北京）科技有限公司, sim = 0.9760900424845506\n",
      "company entity found: 科技->多玛凯拔科技有限公司, sim = 1.0000000094492707\n",
      "company entity found: 爱漫->爱漫科技（北京）有限公司, sim = 0.9739465827942052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text4)\n",
    "output = generateNgrams(segListSanitized, 3)\n",
    "linkCompany(output, model, company_df, 0.95, 0.9)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = '__团队成员#1__，Oracleen创始人。前腾讯电脑管家产品总监、奇虎360产品总监，十年互联网产品经验，熟悉智能硬件，曾研发过国内最早的NAS+路由智能设备。先后在安天实验室、腾讯、奇虎360、盛天网络担任产品总监，带队研发过3款用户过千万的产品。其中包括安天防线、腾讯电脑管家、360网站卫士、易乐玩、易乐游等。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 89. After sanitize, len: 63\n",
      "company entity found: 网络->深圳市正星特网络有限公司, sim = 0.9775604418627177\n",
      "company entity found: 腾讯->腾讯控股有限公司\n",
      ", sim = 0.9712984916123004\n",
      "company entity found: 爱芽->爱芽（北京）科技有限公司, sim = 0.977569224421832\n",
      "company entity found: 互联网->深圳酷旗互联网有限公司, sim = 0.9751275155291305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text5)\n",
    "output = generateNgrams(segListSanitized, 3)\n",
    "linkCompany(output, model, company_df, 0.95, 0.9)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "text6 = '__团队成员#1__，ILIFE智能扫地机创始人。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitize, len: 12. After sanitize, len: 7\n",
      "match 爱乐福\n",
      "company entity found by exact match: 1爱乐福->爱乐福（深圳）科技有限公司\n",
      "match 爱乐福\n",
      "company entity found by exact match: 1爱乐福智能->爱乐福（深圳）科技有限公司\n",
      "match 爱乐福\n",
      "company entity found by exact match: 成员1爱乐福->爱乐福（深圳）科技有限公司\n",
      "match 爱乐福\n",
      "company entity found by exact match: 爱乐福智能扫地机->爱乐福（深圳）科技有限公司\n",
      "match 爱乐福\n",
      "company entity found by exact match: 爱乐福->爱乐福（深圳）科技有限公司\n",
      "match 爱乐福\n",
      "company entity found by exact match: 爱乐福智能->爱乐福（深圳）科技有限公司\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segListSanitized = preprocess(text6)\n",
    "output = generateNgrams(segListSanitized, 3)\n",
    "linkCompany(output, model, company_df, 0.95, 0.87)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handle No.0 text\n",
      "Before sanitize, len: 325. After sanitize, len: 239\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:04:21.161389 sec\n",
      "\n",
      "Handle No.1 text\n",
      "Before sanitize, len: 330. After sanitize, len: 264\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:04:09.386390 sec\n",
      "\n",
      "Handle No.2 text\n",
      "Before sanitize, len: 134. After sanitize, len: 108\n",
      "cost time: 0:02:13.404943 sec\n",
      "\n",
      "Handle No.3 text\n",
      "Before sanitize, len: 187. After sanitize, len: 149\n",
      "cost time: 0:02:27.970139 sec\n",
      "\n",
      "Handle No.4 text\n",
      "Before sanitize, len: 126. After sanitize, len: 94\n",
      "cost time: 0:01:55.641639 sec\n",
      "\n",
      "Handle No.5 text\n",
      "Before sanitize, len: 139. After sanitize, len: 111\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:24.473510 sec\n",
      "\n",
      "Handle No.6 text\n",
      "Before sanitize, len: 140. After sanitize, len: 116\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:14.968615 sec\n",
      "\n",
      "Handle No.7 text\n",
      "Before sanitize, len: 574. After sanitize, len: 411\n",
      "cost time: 0:06:56.226695 sec\n",
      "\n",
      "Handle No.8 text\n",
      "Before sanitize, len: 150. After sanitize, len: 119\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:12.785823 sec\n",
      "\n",
      "Handle No.9 text\n",
      "Before sanitize, len: 115. After sanitize, len: 88\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:03.651254 sec\n",
      "\n",
      "Handle No.10 text\n",
      "Before sanitize, len: 117. After sanitize, len: 84\n",
      "cost time: 0:01:54.336050 sec\n",
      "\n",
      "Handle No.11 text\n",
      "Before sanitize, len: 262. After sanitize, len: 211\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:03:08.400295 sec\n",
      "\n",
      "Handle No.12 text\n",
      "Before sanitize, len: 188. After sanitize, len: 124\n",
      "cost time: 0:02:22.485749 sec\n",
      "\n",
      "Handle No.13 text\n",
      "Before sanitize, len: 467. After sanitize, len: 372\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:05:29.131017 sec\n",
      "\n",
      "Handle No.14 text\n",
      "Before sanitize, len: 181. After sanitize, len: 141\n",
      "cost time: 0:02:37.270539 sec\n",
      "\n",
      "Handle No.15 text\n",
      "Before sanitize, len: 127. After sanitize, len: 85\n",
      "cost time: 0:01:50.525994 sec\n",
      "\n",
      "Handle No.16 text\n",
      "Before sanitize, len: 26. After sanitize, len: 20\n",
      "cost time: 0:00:27.900552 sec\n",
      "\n",
      "Handle No.17 text\n",
      "Before sanitize, len: 135. After sanitize, len: 99\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:06.248838 sec\n",
      "\n",
      "Handle No.18 text\n",
      "Before sanitize, len: 16. After sanitize, len: 8\n",
      "cost time: 0:00:09.513994 sec\n",
      "\n",
      "Handle No.19 text\n",
      "Before sanitize, len: 12. After sanitize, len: 7\n",
      "cost time: 0:00:07.990983 sec\n",
      "\n",
      "Handle No.20 text\n",
      "Before sanitize, len: 81. After sanitize, len: 62\n",
      "cost time: 0:01:24.156623 sec\n",
      "\n",
      "Handle No.21 text\n",
      "Before sanitize, len: 116. After sanitize, len: 90\n",
      "cost time: 0:01:41.511266 sec\n",
      "\n",
      "Handle No.22 text\n",
      "Before sanitize, len: 90. After sanitize, len: 66\n",
      "cost time: 0:01:00.602502 sec\n",
      "\n",
      "Handle No.23 text\n",
      "Before sanitize, len: 310. After sanitize, len: 242\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:04:03.679660 sec\n",
      "\n",
      "Handle No.24 text\n",
      "Before sanitize, len: 90. After sanitize, len: 60\n",
      "cost time: 0:01:18.476869 sec\n",
      "\n",
      "Handle No.25 text\n",
      "Before sanitize, len: 133. After sanitize, len: 109\n",
      "cost time: 0:01:30.938420 sec\n",
      "\n",
      "Handle No.26 text\n",
      "Before sanitize, len: 220. After sanitize, len: 181\n",
      "cost time: 0:02:28.931559 sec\n",
      "\n",
      "Handle No.27 text\n",
      "Before sanitize, len: 152. After sanitize, len: 116\n",
      "cost time: 0:01:58.250166 sec\n",
      "\n",
      "Handle No.28 text\n",
      "Before sanitize, len: 208. After sanitize, len: 166\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:35.677214 sec\n",
      "\n",
      "Handle No.29 text\n",
      "Before sanitize, len: 172. After sanitize, len: 126\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:13.704367 sec\n",
      "\n",
      "Handle No.30 text\n",
      "Before sanitize, len: 119. After sanitize, len: 89\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:01:43.173130 sec\n",
      "\n",
      "Handle No.31 text\n",
      "Before sanitize, len: 99. After sanitize, len: 74\n",
      "cost time: 0:01:20.676763 sec\n",
      "\n",
      "Handle No.32 text\n",
      "Before sanitize, len: 12. After sanitize, len: 7\n",
      "cost time: 0:00:07.789031 sec\n",
      "\n",
      "Handle No.33 text\n",
      "Before sanitize, len: 178. After sanitize, len: 132\n",
      "company entity found: 紫光股份有限公司->紫光股份有限公司, sim = 1.0\n",
      "company entity found: tcl集团股份有限公司->TCL集团股份有限公司, sim = 1.0\n",
      "cost time: 0:02:08.159435 sec\n",
      "\n",
      "Handle No.34 text\n",
      "Before sanitize, len: 11. After sanitize, len: 5\n",
      "cost time: 0:00:04.662021 sec\n",
      "\n",
      "Handle No.35 text\n",
      "Before sanitize, len: 230. After sanitize, len: 172\n",
      "cost time: 0:03:15.576210 sec\n",
      "\n",
      "Handle No.36 text\n",
      "Before sanitize, len: 14. After sanitize, len: 8\n",
      "cost time: 0:00:08.840086 sec\n",
      "\n",
      "Handle No.37 text\n",
      "Before sanitize, len: 10. After sanitize, len: 5\n",
      "cost time: 0:00:04.609028 sec\n",
      "\n",
      "Handle No.38 text\n",
      "Before sanitize, len: 10. After sanitize, len: 5\n",
      "cost time: 0:00:04.641024 sec\n",
      "\n",
      "Handle No.39 text\n",
      "Before sanitize, len: 11. After sanitize, len: 7\n",
      "cost time: 0:00:07.227805 sec\n",
      "\n",
      "Handle No.40 text\n",
      "Before sanitize, len: 161. After sanitize, len: 110\n",
      "cost time: 0:02:06.798597 sec\n",
      "\n",
      "Handle No.41 text\n",
      "Before sanitize, len: 93. After sanitize, len: 68\n",
      "cost time: 0:01:42.462973 sec\n",
      "\n",
      "Handle No.42 text\n",
      "Before sanitize, len: 38. After sanitize, len: 30\n",
      "cost time: 0:00:52.301526 sec\n",
      "\n",
      "Handle No.43 text\n",
      "Before sanitize, len: 11. After sanitize, len: 6\n",
      "cost time: 0:00:08.140990 sec\n",
      "\n",
      "Handle No.44 text\n",
      "Before sanitize, len: 12. After sanitize, len: 6\n",
      "match 爱尔沃德\n",
      "company entity found by exact match: 爱尔沃德->爱尔沃德（杭州）健康科技有限公司\n",
      "cost time: 0:00:08.238001 sec\n",
      "\n",
      "Handle No.45 text\n",
      "Before sanitize, len: 16. After sanitize, len: 10\n",
      "cost time: 0:00:15.344033 sec\n",
      "\n",
      "Handle No.46 text\n",
      "Before sanitize, len: 16. After sanitize, len: 10\n",
      "cost time: 0:00:16.725080 sec\n",
      "\n",
      "Handle No.47 text\n",
      "Before sanitize, len: 12. After sanitize, len: 7\n",
      "cost time: 0:00:17.151260 sec\n",
      "\n",
      "Handle No.48 text\n",
      "Before sanitize, len: 13. After sanitize, len: 8\n",
      "cost time: 0:00:12.932100 sec\n",
      "\n",
      "Handle No.49 text\n",
      "Before sanitize, len: 15. After sanitize, len: 9\n",
      "cost time: 0:00:12.928009 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in member_df.iterrows():\n",
    "    if index == 50:\n",
    "        break\n",
    "    print(f'Handle No.{index} text')\n",
    "    start = datetime.datetime.now()\n",
    "    text = row['Resume']\n",
    "    segListSanitized = preprocess(text)\n",
    "    output = generateNgrams(segListSanitized, 3)\n",
    "    linkCompany(output, model, company_df, 0.96, 0.9)\n",
    "    end = datetime.datetime.now()\n",
    "    print(f'cost time: {end - start} sec')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handle No.45 text\n",
      "Before sanitize, len: 16. After sanitize, len: 10\n",
      "company entity found: 北京->宝希（北京）科技有限公司, sim = 0.9760900424845506\n",
      "company entity found: 发展->深圳市迈迪加科技发展有限公司, sim = 0.9604227663245726\n",
      "sim: 0.9713396702727501\n",
      "company entity found: 爱国者->爱国者电子科技有限公司, sim = 0.9713396702727501\n",
      "company entity found: 科技->多玛凯拔科技有限公司, sim = 1.0000000094492707\n",
      "company entity found: 新能源->上海烯美新能源科技有限公司, sim = 0.9637615946079356\n",
      "cost time: 0:00:13.666006 sec\n",
      "\n",
      "Handle No.46 text\n",
      "Before sanitize, len: 16. After sanitize, len: 10\n",
      "sim: 0.9713396702727501\n",
      "company entity found: 爱国者->爱国者电子科技有限公司, sim = 0.9713396702727501\n",
      "cost time: 0:00:11.050225 sec\n",
      "\n",
      "Handle No.47 text\n",
      "Before sanitize, len: 12. After sanitize, len: 7\n",
      "cost time: 0:00:07.870590 sec\n",
      "\n",
      "Handle No.48 text\n",
      "Before sanitize, len: 13. After sanitize, len: 8\n",
      "cost time: 0:00:09.269059 sec\n",
      "\n",
      "Handle No.49 text\n",
      "Before sanitize, len: 15. After sanitize, len: 9\n",
      "company entity found: 北京->宝希（北京）科技有限公司, sim = 0.9760900424845506\n",
      "company entity found: 科技->多玛凯拔科技有限公司, sim = 1.0000000094492707\n",
      "company entity found: 爱漫->爱漫科技（北京）有限公司, sim = 0.9739465827942052\n",
      "cost time: 0:00:11.122031 sec\n",
      "\n",
      "Handle No.50 text\n",
      "Before sanitize, len: 10. After sanitize, len: 5\n",
      "cost time: 0:00:08.871292 sec\n",
      "\n",
      "Handle No.51 text\n",
      "Before sanitize, len: 11. After sanitize, len: 6\n",
      "cost time: 0:00:06.952300 sec\n",
      "\n",
      "Handle No.52 text\n",
      "Before sanitize, len: 55. After sanitize, len: 42\n",
      "cost time: 0:00:56.236134 sec\n",
      "\n",
      "Handle No.53 text\n",
      "Before sanitize, len: 53. After sanitize, len: 44\n",
      "cost time: 0:00:50.761473 sec\n",
      "\n",
      "Handle No.54 text\n",
      "Before sanitize, len: 89. After sanitize, len: 63\n",
      "company entity found: 网络->深圳市正星特网络有限公司, sim = 0.9775604418627177\n",
      "company entity found: 腾讯->腾讯控股有限公司\n",
      ", sim = 0.9712984916123004\n",
      "company entity found: 爱芽->爱芽（北京）科技有限公司, sim = 0.977569224421832\n",
      "company entity found: 互联网->深圳酷旗互联网有限公司, sim = 0.9751275155291305\n",
      "cost time: 0:01:16.429206 sec\n",
      "\n",
      "Handle No.55 text\n",
      "Before sanitize, len: 60. After sanitize, len: 42\n",
      "company entity found: 爱芽->爱芽（北京）科技有限公司, sim = 0.977569224421832\n",
      "cost time: 0:00:52.327956 sec\n",
      "\n",
      "Handle No.56 text\n",
      "Before sanitize, len: 58. After sanitize, len: 38\n",
      "company entity found: 爱芽->爱芽（北京）科技有限公司, sim = 0.977569224421832\n",
      "cost time: 0:00:44.841791 sec\n",
      "\n",
      "Handle No.57 text\n",
      "Before sanitize, len: 27. After sanitize, len: 17\n",
      "company entity found: 爱芽->爱芽（北京）科技有限公司, sim = 0.977569224421832\n",
      "cost time: 0:00:33.471164 sec\n",
      "\n",
      "Handle No.58 text\n",
      "Before sanitize, len: 19. After sanitize, len: 12\n",
      "cost time: 0:00:13.389921 sec\n",
      "\n",
      "Handle No.59 text\n",
      "Before sanitize, len: 11. After sanitize, len: 6\n",
      "cost time: 0:00:05.508220 sec\n",
      "\n",
      "Handle No.60 text\n",
      "Before sanitize, len: 195. After sanitize, len: 148\n",
      "company entity found: 上海->馥德（上海）科技有限公司, sim = 0.9805150951364708\n",
      "company entity found: 中国->尚科宁家（中国）科技有限公司, sim = 0.9905265283315191\n",
      "cost time: 0:01:58.520626 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in member_df.iterrows():\n",
    "    if index < 45:\n",
    "        continue\n",
    "    \n",
    "    if index > 60:\n",
    "        break\n",
    "    print(f'Handle No.{index} text')\n",
    "    start = datetime.datetime.now()\n",
    "    text = row['Resume']\n",
    "    segListSanitized = preprocess(text)\n",
    "    output = generateNgrams(segListSanitized, 3)\n",
    "    linkCompany(output, model, company_df, 0.96, 0.9)\n",
    "    end = datetime.datetime.now()\n",
    "    print(f'cost time: {end - start} sec')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
