{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Match Company\n",
    "In this notebook, I try to deal with company matching problem.\n",
    "E.g, 上海速必达有限公司. Cannot find `速必达`'s embedding in dictionary. Thus the generated vector may lose key information.\n",
    "\n",
    "Solution: Can ignore the key word `速必达`. We detect the company name structure, then the middle part can be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = KeyedVectors.load('./test_50.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case1\n",
    "entity = `上海爱笔有限公司`\n",
    "In this case, every word in this entity could be found in vocabulary.\n",
    "Given the same term, the similarity of their embedding vectors is approximately 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = '上海爱笔有限公司'\n",
    "term2 = '上海'\n",
    "term3 = '爱笔'\n",
    "term4 = '有限公司'\n",
    "entity = '爱笔（北京）智能科技有限公司'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCompanyEmbeddings(name):\n",
    "    words = jieba.cut(name, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    for word in word_list:\n",
    "        if word in model.vocab:\n",
    "            v += model[word]\n",
    "    \n",
    "    v /= len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTermEmbeddings(term):\n",
    "    words = jieba.cut(term, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    for word in word_list:\n",
    "        print(word)\n",
    "        if word in model.vocab:\n",
    "            v += model[word]\n",
    "        else:\n",
    "            print(f'{word} not found')\n",
    "    v /= len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(a, b):\n",
    "    vector_a = np.mat(a)\n",
    "    vector_b = np.mat(b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "entity_vec = generateCompanyEmbeddings(entity)\n",
    "print(entity_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "term2_vec = model[term2] # 上海\n",
    "term4_vec = model[term4] # 有限公司\n",
    "print(term2_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = model['艾美特']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('伊莱克斯', 0.7312238812446594),\n",
       " ('格兰仕', 0.717694103717804),\n",
       " ('冷风扇', 0.6984611749649048),\n",
       " ('法罗力', 0.6955032348632812),\n",
       " ('志高空调', 0.6942696571350098),\n",
       " ('ao史密斯', 0.6932370662689209),\n",
       " ('落地扇', 0.6921243071556091),\n",
       " ('空调质量', 0.6915013194084167),\n",
       " ('富士宝', 0.6913032531738281),\n",
       " ('荣事达', 0.6868325471878052)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('艾美特')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1_vec = generateCompanyEmbeddings(term1)\n",
    "term3_vec = generateCompanyEmbeddings(term3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9225701537699091\n"
     ]
    }
   ],
   "source": [
    "sim1 = calculate_cosine_similarity(entity_vec, term1_vec)\n",
    "print(sim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7808995749093834\n"
     ]
    }
   ],
   "source": [
    "sim3 = calculate_cosine_similarity(entity_vec, term3_vec)\n",
    "print(sim3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8836462869842496\n"
     ]
    }
   ],
   "source": [
    "sim4 = calculate_cosine_similarity(entity_vec, term4_vec)\n",
    "print(sim4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case2\n",
    "entity: `多玛凯拔科技有限公司`. The company name, `多玛凯拔`, which is the most descriptive word, cannot be found in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2 = '多玛凯拔科技有限公司'\n",
    "term5 = '多玛凯拔'\n",
    "term6 = '科技'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2_vec = generateCompanyEmbeddings(entity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "term5_vec = generateCompanyEmbeddings(term5)\n",
    "sim5 = calculate_cosine_similarity(entity2_vec, term5_vec)\n",
    "print(sim5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "科技\n",
      "0.9284849222005065\n"
     ]
    }
   ],
   "source": [
    "term6_vec = generateTermEmbeddings(term6)\n",
    "sim6 = calculate_cosine_similarity(entity2_vec, term6_vec)\n",
    "print(sim6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# if sim5 > 0.9, exact match\n",
    "idx = entity2.find(term5)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractKeyword(term):\n",
    "    '''\n",
    "    Extract keyword in a term, whose embedding can not be found in vocabulary\n",
    "    Return a list\n",
    "    '''\n",
    "    words = jieba.cut(term, cut_all=False)\n",
    "    word_list = list(words)\n",
    "    v = np.zeros((200))\n",
    "    keyword = []\n",
    "    for word in word_list:\n",
    "        if word not in model.vocab:\n",
    "            print(f'keyword found: {word}')\n",
    "            keyword.append(word)\n",
    "    return keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(entity, term):\n",
    "    keyword = extractKeyword(term)\n",
    "    is_match = False\n",
    "    for key in keyword:\n",
    "        idx = entity.find(key)\n",
    "        if idx != -1:\n",
    "            is_match = True\n",
    "            print(f'match {key}')\n",
    "    return is_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword found: 多玛凯拔\n",
      "match 多玛凯拔\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "is_match = exact_match(entity2, term5)\n",
    "print(is_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "is_match2 = exact_match(entity2, term6)\n",
    "print(is_match2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case3\n",
    "entity: `广州酷刻科技有限公司`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity3 = '广州酷刻科技有限公司'\n",
    "term7 = '广州'\n",
    "term8 = '酷刻'\n",
    "term9 = '有限公司'\n",
    "term10 = '广州酷刻科技'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity3_vec = generateCompanyEmbeddings(entity3)\n",
    "term7_vec = generateCompanyEmbeddings(term7)\n",
    "term8_vec = generateCompanyEmbeddings(term8)\n",
    "term9_vec = generateCompanyEmbeddings(term9)\n",
    "term10_vec = generateCompanyEmbeddings(term10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798465039357534\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "sim7 = calculate_cosine_similarity(entity3_vec, term7_vec)\n",
    "print(sim7)\n",
    "is_match7 = exact_match(entity3, term7)\n",
    "print(is_match7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "keyword found: 酷刻\n",
      "match 酷刻\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sim8 = calculate_cosine_similarity(entity3_vec, term8_vec)\n",
    "print(sim8)\n",
    "is_match8 = exact_match(entity3, term8)\n",
    "print(is_match8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890014971996258\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "sim9 = calculate_cosine_similarity(entity3_vec, term9_vec)\n",
    "print(sim9)\n",
    "is_match9 = exact_match(entity3, term9)\n",
    "print(is_match9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642831390531543\n",
      "keyword found: 酷刻\n",
      "match 酷刻\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sim10 = calculate_cosine_similarity(entity3_vec, term10_vec)\n",
    "print(sim10)\n",
    "is_match10 = exact_match(entity3, term10)\n",
    "print(is_match10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case4\n",
    "entity: `爱国者电子科技有限公司`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity4 = '爱国者电子科技有限公司'\n",
    "term11 = '爱国者'\n",
    "entity4_vec = generateCompanyEmbeddings(entity4)\n",
    "term11_vec = generateCompanyEmbeddings(term11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8100053842362365\n"
     ]
    }
   ],
   "source": [
    "sim11 = calculate_cosine_similarity(term11_vec, entity4_vec)\n",
    "print(sim11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case5\n",
    "entity: `爱乐福（深圳）科技有限公司`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity5 = '爱乐福（深圳）科技有限公司'\n",
    "term12 = '爱乐福'\n",
    "entity5_vec = generateCompanyEmbeddings(entity5)\n",
    "term12_vec = generateCompanyEmbeddings(term12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8778953803630984\n"
     ]
    }
   ],
   "source": [
    "sim12 = calculate_cosine_similarity(term12_vec, entity5_vec)\n",
    "print(sim12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word '爱乐福' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-c85e23040569>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mterm12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, entities)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\梁育诚\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word '爱乐福' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "ff = model[term12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
