{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Notebook\n",
    "In this notebook, I try to use gensim to do word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From Pre-trained Txt File\n",
    "First I have to load from pretrained data from txt file.\n",
    "Load all data may take more than 30mins on my laptop, so it would be better to set a limit.\n",
    "\n",
    "Also, I save model as a bin file for later use, which will be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "file = 'data/Tencent_AILab_ChineseEmbedding/Tencent_AILab_ChineseEmbedding.txt'\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(file, binary=False, limit=100000)\n",
    "wv_from_text.init_sims(replace=True) # save memory to run faster\n",
    "wv_from_text.save('./test.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('曼联', 0.9391189813613892),\n",
       " ('切尔西', 0.9346709847450256),\n",
       " ('利物浦', 0.9224727153778076),\n",
       " ('热刺', 0.913425087928772),\n",
       " ('温格', 0.9049314856529236),\n",
       " ('曼城', 0.9032983779907227),\n",
       " ('西布朗', 0.8680431246757507),\n",
       " ('英超', 0.863417387008667),\n",
       " ('斯旺西', 0.8625228404998779),\n",
       " ('利物浦的', 0.8616222143173218)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_text.most_similar('阿森纳')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From bin File\n",
    "In practical use, I load model from bin file, which is fast and can be finish in few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('./test.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Function Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_similar\n",
    "This function accepts a query word, and return all relative words based on their similarities. Fro similarity here, the model use Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('在中国', 0.7863314747810364),\n",
       " ('中国国内', 0.7796300053596497),\n",
       " ('说中国', 0.7657051086425781),\n",
       " ('其他国家', 0.765122652053833),\n",
       " ('国家', 0.7572988271713257),\n",
       " ('中国本土', 0.7543554306030273),\n",
       " ('美国', 0.7531554698944092),\n",
       " ('中国目前', 0.7521167993545532),\n",
       " ('中国发展', 0.750878095626831),\n",
       " ('目前中国', 0.7493101954460144)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('中国')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get embedding vector\n",
    "I can get a word's embedding vector to compute different scores based on different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "[ 0.0577162  -0.06945625  0.05540956  0.11758969  0.09546565  0.03729196\n",
      " -0.02974207  0.06095821 -0.01023129  0.01493978  0.04045184 -0.00883508\n",
      " -0.11121243  0.0104354   0.02105665 -0.00915447 -0.06020505 -0.19626671\n",
      " -0.01872811 -0.03399367 -0.05467222 -0.06345588 -0.03076352 -0.00747567\n",
      "  0.02761459  0.00362954 -0.05004403  0.07759292  0.0802442   0.08721583\n",
      " -0.02959119  0.01097502 -0.0118164   0.01257534  0.01229093 -0.0234512\n",
      "  0.07917012 -0.00348566 -0.18709278  0.02513031 -0.09646855  0.05539405\n",
      "  0.07661617  0.02312359 -0.04140972 -0.01033562 -0.03993502 -0.21838924\n",
      " -0.0030519  -0.06632831 -0.07338238  0.04787275 -0.05623603  0.04381279\n",
      "  0.09508055 -0.02240663 -0.02314732  0.04810788  0.0465389   0.08131615\n",
      "  0.05668471  0.06790247  0.02324101  0.144167    0.01661706  0.08001515\n",
      " -0.00941637  0.01126704  0.07383653 -0.0613494  -0.06450471 -0.09825138\n",
      "  0.08055142 -0.01678923 -0.11295786  0.01174735  0.01541066  0.16284311\n",
      "  0.15695193 -0.0534214   0.04785389  0.11198051  0.03352188 -0.00189356\n",
      "  0.1276187  -0.03871889 -0.03219806  0.03429846 -0.00776069 -0.07812645\n",
      "  0.00602379  0.00917759  0.01901435 -0.00355137  0.15733825 -0.00175515\n",
      " -0.0692418  -0.01756216 -0.19529973  0.06082467  0.00142024 -0.01487499\n",
      " -0.12213544 -0.01682664 -0.01354144  0.14030507  0.02496878 -0.1226261\n",
      " -0.07445219  0.03779994 -0.06561986 -0.05739012  0.05955957 -0.06092901\n",
      "  0.02262746 -0.03683142 -0.04164729 -0.03536616 -0.02884107 -0.09027929\n",
      "  0.04514816 -0.02929856 -0.10186755 -0.05934512  0.07435486  0.07423531\n",
      "  0.04769693  0.03685819 -0.02649336  0.05612927 -0.02153087 -0.01746057\n",
      "  0.0995025   0.0350279  -0.11184362  0.04158219 -0.0193596  -0.06248431\n",
      " -0.05472818 -0.00854062 -0.09845427 -0.14392    -0.10366346 -0.08265182\n",
      "  0.00935584  0.06202682  0.02244191  0.05638539 -0.06519643  0.1244138\n",
      " -0.01056802 -0.09150181 -0.06969382 -0.03662427 -0.07125065 -0.01809814\n",
      " -0.00958459  0.09938691  0.0302826   0.04397887  0.12662005 -0.02949476\n",
      "  0.05494416  0.06212325  0.10882427 -0.03173539 -0.08505246  0.02243674\n",
      " -0.06824407  0.0030087   0.03828999 -0.0229864  -0.08671149  0.01457962\n",
      "  0.02478505 -0.06596389 -0.11839335  0.07153262  0.05084951  0.12319462\n",
      " -0.11778193 -0.01025562 -0.0733185   0.10716463  0.0281314   0.07495745\n",
      " -0.0576146   0.1240804   0.0482615   0.02752759  0.0415463   0.00265858\n",
      "  0.09036567 -0.02339188  0.12578233  0.10391198  0.02501167 -0.08591636\n",
      "  0.01404821  0.04168622]\n"
     ]
    }
   ],
   "source": [
    "v = model['中国']\n",
    "print(v.shape)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check whether a word is in model\n",
    "This dataset may not cover all the words we query. And due to the simplificatio of the dataset, I probably can not find the query word. I should check the existence first in order to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not IN Vocabulary\n"
     ]
    }
   ],
   "source": [
    "if 'lyc' in model.vocab:\n",
    "    print('In Vocabulary')\n",
    "else:\n",
    "    print('Not IN Vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
